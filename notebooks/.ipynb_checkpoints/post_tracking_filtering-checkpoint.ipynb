{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ef22f5-177f-4de3-a1da-45a7b78a3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913716b-cfcf-4885-a3c8-7185f0efb955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4915f48-6631-46bb-a836-3d0f6804b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d3ddb-65ba-48e3-a7d5-5301a61f2bda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "from framegrabber.frame_grabber import FrameGrabber\n",
    "\n",
    "from detection.ultralytics_detectors import UltralyticsDetector\n",
    "\n",
    "from tracking.track import Tracker\n",
    "\n",
    "from counting.count_config_loader import CountingConfigLoader\n",
    "from counting.count_visualizer import CountVisualizer\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "my_model = UltralyticsDetector(\"yolo11n_finetuned.pt\" , conf=0.50)         # rtdetr-l.pt  yolo11n.pt yolo26n.pt yolo11n_finetuned\n",
    "coco_vehicles = [1, 2, 3, 5, 7]\n",
    "vehicles_4_wheels = [2, 5, 7]\n",
    "device = my_model.predictor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd0da8-ad93-4c38-bbae-fafee711fe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.predictor.args.conf , my_model.predictor.args.imgsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f681cc-869b-4baf-b639-442bb3ed32ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detection.torchvision_detectors import TorchvisionDetector\n",
    "\n",
    "det = TorchvisionDetector(\n",
    "    \"fasterrcnn_resnet50_fpn_v2\",\n",
    "    conf=0.6,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "# detections = det.detect_to_track(frame.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230f91d-982b-4d45-a1d7-cea3933eb019",
   "metadata": {},
   "source": [
    "* yolo26n: YOLO26n summary (fused): 122 layers, 2,408,932 parameters, 0 gradients, 5.4 GFLOPs\n",
    "* YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
    "* YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189114a-35bf-4206-9498-c9be34853dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7bb282-6231-4b69-bbeb-3530e863f132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa97077-70d5-4291-9c9d-86fd7c074617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f2035-213d-4b17-8c76-d88f71a87eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_counters(*counters):\n",
    "    \"\"\"\n",
    "    Accepts:\n",
    "      ([roi1, roi2], global_ctr)\n",
    "      or\n",
    "      ([roi1, roi2, global_ctr],)\n",
    "\n",
    "    Returns:\n",
    "      flat, ordered list of counter objects\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- flatten ----\n",
    "    flat = []\n",
    "    for c in counters:\n",
    "        if isinstance(c, (list, tuple)):\n",
    "            flat.extend(c)\n",
    "        else:\n",
    "            flat.append(c)\n",
    "\n",
    "    # ---- semantic order ----\n",
    "    def key(ctr):\n",
    "        info = ctr.get_area_info()\n",
    "        # ROI / line first, global last\n",
    "        if info.get(\"polygon\") is not None or info.get(\"line\") is not None:\n",
    "            return (0, info.get(\"name\", \"\"))\n",
    "        return (1, info.get(\"name\", \"\"))\n",
    "\n",
    "    return sorted(flat, key=key)\n",
    "\n",
    "    \n",
    "count_vis = CountVisualizer(\n",
    "    show_legend=False,   # hide class legend\n",
    "    show_summary=True    # keep total summary box\n",
    ")\n",
    "\n",
    "counter_load = CountingConfigLoader()\n",
    "\n",
    "counters = counter_load.load_counting_areas()\n",
    "\n",
    "counters = ordered_counters(*counters)\n",
    "counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f54edb-409f-410f-a408-db99b5f50140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.profilers import Profile\n",
    "\n",
    "device = my_model.predictor.device\n",
    "inf_profile = Profile(device=device)\n",
    "pre_profile = Profile(device=device)\n",
    "post_profile = Profile(device=device)\n",
    "track_profile = Profile()\n",
    "count_profile = Profile()\n",
    "grabber_profile = Profile()\n",
    "plot_profile = Profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d86e0-32a9-4469-bc6c-ae5648eefd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_method = \"bytetrack\"\n",
    "tracker = Tracker(tracking_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b0672-a2d7-4c35-b1c8-6e1b560bcd4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# source = r\"C:\\Users\\hamza\\Datasets\\TrafficDatasets\\IMAROC_2\\kech66.mp4\"                   # 0 \"kech.mp4\" , \"vid1.mp4\"\n",
    "# stride = 3\n",
    "# stride_method = \"periodic_stride\"             # \"burst_stride\", \"periodic_stride\", \"random_sampling\"\n",
    "\n",
    "# frame_grabber = FrameGrabber(source, stride=stride, stride_method=stride_method)\n",
    "\n",
    "\n",
    "# if not frame_grabber.open():\n",
    "#     raise RuntimeError(\"Failed to open source\")\n",
    "# # ensure window exists (main thread)\n",
    "# if frame_grabber._grabber_mode==\"queue\":\n",
    "# # start producer\n",
    "#     frame_grabber.start()\n",
    "\n",
    "# try:\n",
    "#     with torch.inference_mode():\n",
    "#         while True:\n",
    "#             with grabber_profile:\n",
    "#                 # try to get a frame but don't block forever\n",
    "#                 frame = frame_grabber.get_frame(timeout=0.1)  # <-- short timeout keeps loop responsive\n",
    "                    \n",
    "#             if frame is not None:\n",
    "#                 print(f\"frame_grabber index: {frame.read_idx}\")\n",
    "\n",
    "#                 with inf_profile:\n",
    "#                     ready_to_track_array = my_model.detect_to_track(frame.data)\n",
    "                    \n",
    "#                 with track_profile:\n",
    "#                     res = tracker.update(ready_to_track_array , frame.data)\n",
    "                    \n",
    "#                 det_array_plot = my_model.plot()\n",
    "\n",
    "\n",
    "#                 with count_profile:\n",
    "#                     g_count = counters[0].count(res)\n",
    "                    \n",
    "#                 # mark processed & show\n",
    "#                 frame_grabber.mark_processed(frame)\n",
    "\n",
    "                \n",
    "#             else:\n",
    "#                 # no frame this iteration (timeout), you may choose to display a placeholder\n",
    "#                 # or simply continue — but still poll for key events below\n",
    "#                 break\n",
    "\n",
    "# finally:\n",
    "#     frame_grabber.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51704155-cfad-470c-82d1-1eb15a234733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_count.total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cffd98-0beb-4488-9fcd-572ecdfd6e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd6cfd9-94fd-4809-a3e3-8aec7c7b6647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source = r\"C:\\Users\\hamza\\Datasets\\TrafficDatasets\\IMAROC_2\\kech37.mp4\"                   # 0 \"kech.mp4\" , \"vid1.mp4\"\n",
    "\n",
    "# --- Video writer setup ---\n",
    "output_path = \"output_counting_37_.mp4\"\n",
    "\n",
    "fps = 30\n",
    "\n",
    "# Get frame size (wait until first frame if needed)\n",
    "ret, test_cap = cv2.VideoCapture(source).read()\n",
    "h, w = test_cap.shape[:2]\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # widely supported\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n",
    "\n",
    "assert video_writer.isOpened(), \"Failed to open VideoWriter\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stride = 2\n",
    "stride_method = \"periodic_stride\"             # \"burst_stride\", \"periodic_stride\", \"random_sampling\"\n",
    "\n",
    "frame_grabber = FrameGrabber(source, stride=stride, stride_method=stride_method)\n",
    "\n",
    "\n",
    "if not frame_grabber.open():\n",
    "    raise RuntimeError(\"Failed to open source\")\n",
    "# ensure window exists (main thread)\n",
    "cv2.namedWindow('BoXMOT + ultralytics', cv2.WINDOW_NORMAL)\n",
    "if frame_grabber._grabber_mode==\"queue\":\n",
    "# start producer\n",
    "    frame_grabber.start()\n",
    "\n",
    "try:\n",
    "    with torch.inference_mode():\n",
    "        while True:\n",
    "            with grabber_profile:\n",
    "                # try to get a frame but don't block forever\n",
    "                frame = frame_grabber.get_frame(timeout=0.1)  # <-- short timeout keeps loop responsive\n",
    "                    \n",
    "            if frame is not None:\n",
    "                print(f\"frame_grabber index: {frame.read_idx}\")\n",
    "\n",
    "                with inf_profile:\n",
    "                    ready_to_track_array = my_model.detect_to_track(frame.data)\n",
    "   \n",
    "                with track_profile:\n",
    "                    res = tracker.update(ready_to_track_array , frame.data)\n",
    "                    # print(f\"tracking array: {res} for counter: {counters[2]}\")\n",
    "                # det_array_plot = my_model.plot()\n",
    "                # det_array_plot = det.plot(frame.data, detections)\n",
    "                \n",
    "                track_array_plot = tracker.tracker.plot_results(frame.data, show_trajectories=True)\n",
    "\n",
    "                with count_profile:\n",
    "                    g_count = counters[2].count(res)\n",
    "                    # roi1_count = counters[0].count(res , current_frame = frame.read_idx)\n",
    "                    # roi2_count = counters[1].count(res , current_frame = frame.read_idx)\n",
    "                    \n",
    "                with plot_profile:\n",
    "                    count_plot = count_vis.render(track_array_plot, *counters)\n",
    "\n",
    "\n",
    "                # --- WRITE FRAME TO VIDEO ---\n",
    "                video_writer.write(count_plot)\n",
    "\n",
    "    \n",
    "                    \n",
    "                # mark processed & show\n",
    "                frame_grabber.mark_processed(frame)\n",
    "\n",
    "                cv2.imshow('BoXMOT + ultralytics', count_plot)\n",
    "                \n",
    "            else:\n",
    "                # no frame this iteration (timeout), you may choose to display a placeholder\n",
    "                # or simply continue — but still poll for key events below\n",
    "                pass\n",
    "\n",
    "            # ALWAYS poll keyboard events so 'q' is detected even when no frame was available\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                # stop producer and break loop\n",
    "                if frame_grabber._grabber_mode==\"queue\":\n",
    "                    frame_grabber.stop(wait=True)\n",
    "                break\n",
    "    \n",
    "                # optional: also break when producer finished (sentinel)\n",
    "                if frame_grabber._grabber_mode==\"queue\":\n",
    "                    if frame is None and frame_grabber._stop_event.is_set():\n",
    "                        break\n",
    "finally:\n",
    "    frame_grabber.release()\n",
    "    video_writer.release()   # <-- ADD THIS\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1bb123-49dd-4602-9982-6969a35d9577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c377a6-9773-4282-901f-7819eab1023d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counters[0].id_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239ada56-6fb4-4b02-a812-4a10d43b88d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counters[2].id_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941db2e-70e9-4fda-8e44-813ad5cb0d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = r\"C:\\Users\\hamza\\Datasets\\TrafficDatasets\\IMAROC_2\\kech37.mp4\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f551a0-ada1-40b1-b276-f05eefea00b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_count , roi1_count , roi2_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af078d6a-a7c3-4d9f-bf76-7c58d7cf69dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f43721-9021-429f-a20e-b7ad7aa8ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_count.total_count , g_count.counts_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725a1bf-6166-46f1-9416-ec04a6d9bd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e633a80-7fa4-4db6-b489-602f713fb748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.shape_setter import PointSelector , LineSelector , TwoLineSelector , PolygonSelector , RectangleSelector , OBBSelector\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "stride = 1\n",
    "stride_method = \"periodic_stride\"             # \"burst_stride\", \"periodic_stride\", \"random_sampling\"\n",
    "\n",
    "cap = cv2.VideoCapture(source)\n",
    "ok, first_frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if not ok or first_frame is None:\n",
    "    print(\"Failed to read example frame; please provide a valid path ('kech.mp4' used in example).\")\n",
    "else:\n",
    "    # line\n",
    "    line_sel = LineSelector(max_display_size=900, auto_confirm=True, preview_wait_secs=None)\n",
    "    line = line_sel.select_line(first_frame)\n",
    "    print(\"Selected line:\", line)\n",
    "\n",
    "    # # two lines\n",
    "    # two_sel = TwoLineSelector(max_display_size=900, auto_confirm=True, preview_wait_secs=None)\n",
    "    # two = two_sel.select_two_lines(first_frame)\n",
    "    # print(\"Selected two lines:\", two)\n",
    "\n",
    "    # #polygon\n",
    "    # poly_sel = PolygonSelector(max_display_size=900, min_points=4, auto_close_on_click_near_first=True,\n",
    "    #                            close_pixel_radius=12, preview_wait_secs=None)\n",
    "    # poly = poly_sel.select_polygon(first_frame)\n",
    "    # print(\"Selected polygon:\", poly)\n",
    "\n",
    "    # # rectangle\n",
    "    # rect_sel = RectangleSelector(max_display_size=900, auto_confirm=True, preview_wait_secs=None)\n",
    "    # rect = rect_sel.select_rectangle(first_frame)\n",
    "    # if rect is None:\n",
    "    #     print(\"Cancelled\")\n",
    "    # else:\n",
    "    #     print(\"Selected rectangle:\", rect)\n",
    "\n",
    "\n",
    "    # # # obb£\n",
    "    # obb_selector = OBBSelector()\n",
    "    # obb_points = obb_selector.select_obb(first_frame)\n",
    "    # if obb_points is not None:\n",
    "    #     print(\"Selected OBB points:\", obb_points)\n",
    "    # else:\n",
    "    #     print(\"Selection cancelled\")\n",
    "\n",
    "\n",
    "    # selector = PointSelector()\n",
    "    # pt = selector.select_point(first_frame)\n",
    "    # print(\"Selected point:\", pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6345e6-4cf7-4531-b6b2-27e7a311b636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e6f58aa-787c-4b48-95db-1ca150c16507",
   "metadata": {},
   "source": [
    "* I need the sys metrics file\n",
    "* I need the actual counts\n",
    "* I need to understand why counting fails ?????? or it takes a very long time to operate !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66fe6db-4948-41a2-81cf-56c9fe807c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
