{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbffbb65-64ce-4260-bea9-23ccc8a06668",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2bd7e2-74ec-4b86-bb3f-70c3a2ae4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64fb30c-f0ab-4eb3-a3b7-17b70a00b505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Sequence, Tuple, List, Dict, Any, Optional , Iterator\n",
    "import re\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import math\n",
    "import os\n",
    "import ast\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "base_path = Path(r\"C:\\Users\\hamza\\Datasets\\TrafficDatasets\\UA_DETRAC_Original\")\n",
    "\n",
    "save_path = Path(\"uadetrac_dataset/ua_detrac_annotations.csv\")\n",
    "annotations_df = pd.read_csv(save_path)\n",
    "\n",
    "save_path = Path(\"uadetrac_dataset/uadetrac_vid_roi_ann.csv\")\n",
    "geometry_df = pd.read_csv(save_path, converters={\"ROI\": eval, \"line\": eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb821a7-e11d-401f-9cbc-b11260b6cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e1c0a7-0297-4a47-b5df-5266fa176db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7813d2b-1808-4415-ab68-add2e7d8ca30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---- 1) get_frame_annotations ------------------------------------------------\n",
    "def get_frame_annotations(sequence: str, frame: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return subset of annotations_df for given sequence and frame.\n",
    "    \"\"\"\n",
    "    sel = annotations_df[\n",
    "        (annotations_df['sequence'].astype(str) == str(sequence)) &\n",
    "        (annotations_df['frame'].astype(int) == int(frame))\n",
    "    ].copy()\n",
    "    return sel\n",
    "\n",
    "# ---- 2) find_frame_image_path ------------------------------------------------\n",
    "def find_frame_image_path(sequence: str, frame: int , base_path: Path = base_path) -> Path:\n",
    "    \"\"\"\n",
    "    Locate the image file for a given DETRAC sequence and frame number.\n",
    "    Raises FileNotFoundError if not found.\n",
    "    \"\"\"\n",
    "    base_path = Path(base_path)\n",
    "    # common candidate folders\n",
    "    candidates = [\n",
    "        base_path / \"DETRAC-Images\" / \"DETRAC-Images\" / sequence,\n",
    "    ]\n",
    "    seq_dir = None\n",
    "    for c in candidates:\n",
    "        if c.exists() and c.is_dir():\n",
    "            seq_dir = c\n",
    "            break\n",
    "    if seq_dir is None:\n",
    "        matches = list(base_path.rglob(sequence))\n",
    "        seq_dir = matches[0] if matches else None\n",
    "    if seq_dir is None or not seq_dir.is_dir():\n",
    "        raise FileNotFoundError(f\"Sequence folder '{sequence}' not found under {base_path}\")\n",
    "\n",
    "    # file name heuristics\n",
    "    def _padded(n, width=5): return str(n).zfill(width)\n",
    "    patterns = [\n",
    "        f\"img{_padded(frame)}\",\n",
    "        f\"img{frame}\",\n",
    "        f\"frame_{_padded(frame)}\",\n",
    "        f\"frame_{frame}\",\n",
    "        f\"{_padded(frame)}\",\n",
    "        str(frame)\n",
    "    ]\n",
    "    img_path = None\n",
    "    files = sorted([p for p in seq_dir.iterdir() if p.is_file()])\n",
    "    for p in files:\n",
    "        name = p.stem.lower()\n",
    "        if any(pat in name for pat in patterns) and p.suffix.lower() in ('.jpg','.jpeg','.png','.bmp','.tif','.tiff'):\n",
    "            img_path = p\n",
    "            break\n",
    "\n",
    "    # fallback: index = frame-1\n",
    "    if img_path is None:\n",
    "        idx = frame - 1\n",
    "        image_files = [p for p in files if p.suffix.lower() in ('.jpg','.jpeg','.png','.bmp','.tif','.tiff')]\n",
    "        if 0 <= idx < len(image_files):\n",
    "            img_path = image_files[idx]\n",
    "\n",
    "    if img_path is None:\n",
    "        raise FileNotFoundError(f\"Could not locate image for sequence={sequence} frame={frame} in {seq_dir}\")\n",
    "\n",
    "    return img_path\n",
    "\n",
    "# ---- 3) annotate_image -------------------------------------------------------\n",
    "def annotate_image(image_rgb: np.ndarray,\n",
    "                   anns: pd.DataFrame,\n",
    "                   box_thickness: int = 2,\n",
    "                   font_scale: float = 0.6) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Draw bounding boxes, video_track_id and category onto an RGB image and return annotated RGB image.\n",
    "    \"\"\"\n",
    "    img = image_rgb.copy()\n",
    "    H, W = img.shape[:2]\n",
    "\n",
    "    # build category -> color map (deterministic)\n",
    "    unique_cats = sorted(anns['category'].dropna().unique().astype(str)) if not anns.empty else []\n",
    "\n",
    "    cmap = plt.colormaps.get_cmap('tab10')\n",
    "    unique_cats = sorted(anns['category'].dropna().unique().astype(str)) if not anns.empty else []\n",
    "    cat2color = {\n",
    "        cat: tuple(int(c * 255) for c in cmap(i % cmap.N)[:3])\n",
    "        for i, cat in enumerate(unique_cats)\n",
    "    }\n",
    "\n",
    "    for _, r in anns.iterrows():\n",
    "        x = float(r.get('bbox_x', 0)); y = float(r.get('bbox_y', 0))\n",
    "        w_box = float(r.get('bbox_w', 0)); h_box = float(r.get('bbox_h', 0))\n",
    "        x1 = int(round(x)); y1 = int(round(y))\n",
    "        x2 = int(round(x + w_box)); y2 = int(round(y + h_box))\n",
    "        # clamp\n",
    "        x1 = max(0, min(W-1, x1)); x2 = max(0, min(W-1, x2))\n",
    "        y1 = max(0, min(H-1, y1)); y2 = max(0, min(H-1, y2))\n",
    "\n",
    "        cat = str(r.get('category', 'unknown'))\n",
    "        color = cat2color.get(cat, (255, 0, 255))\n",
    "        # draw rectangle (RGB)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness=box_thickness)\n",
    "\n",
    "        # label: track id + category\n",
    "        track = r.get('video_track_id', r.get('track_id', None))\n",
    "        try:\n",
    "            track_label = f\"{int(track)}\" if (track is not None and not pd.isna(track)) else \"\"\n",
    "        except Exception:\n",
    "            track_label = str(track)\n",
    "        label = f\"{track_label} {cat}\".strip()\n",
    "\n",
    "        ((tw, th), _) = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, 1)\n",
    "        bg_y1 = max(0, y1 - th - 6); bg_y2 = y1\n",
    "        bg_x1 = x1; bg_x2 = x1 + tw + 8\n",
    "        cv2.rectangle(img, (bg_x1, bg_y1), (bg_x2, bg_y2), color, -1)\n",
    "        cv2.putText(img, label, (x1 + 4, y1 - 4), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255,255,255), thickness=1, lineType=cv2.LINE_AA)\n",
    "\n",
    "    return img\n",
    "\n",
    "# ---- 4) show_image -----------------------------------------------------------\n",
    "def show_image(img_rgb: np.ndarray, title: str = \"\", save_path: Optional[Path] = None, figsize: Tuple[int,int] = (12,8)) -> None:\n",
    "    \"\"\"\n",
    "    Display an RGB image with matplotlib and optionally save it (PNG/JPG).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    if save_path:\n",
    "        save_path = Path(save_path)\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        # convert RGB -> BGR for cv2.imwrite\n",
    "        cv2.imwrite(str(save_path), cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sequence = \"MVI_39031\"\n",
    "frame = 250\n",
    "\n",
    "anns = get_frame_annotations(sequence=sequence, frame=frame)\n",
    "img_path = find_frame_image_path(sequence=sequence, frame=frame) \n",
    "img = cv2.cvtColor(cv2.imread(str(img_path)), cv2.COLOR_BGR2RGB)\n",
    "annotated = annotate_image(img, anns)\n",
    "show_image(annotated, title=f\"video {sequence} frame {frame}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef392ea-ff73-4416-8289-175af571353e",
   "metadata": {},
   "source": [
    "## GeoAnnotation Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e914c-5991-4918-9e7b-aa4601f03d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from framegrabber.frame_grabber import UADETRACFrameGrabber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ceeb54-2a98-4651-8388-f6118123a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = UADETRACFrameGrabber()         \n",
    "fg.open_sequence(\"MVI_20051\")      \n",
    "# random access (DETRAC 1-based)\n",
    "idx, frame, path = fg.get_frame(10)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40ec7f-f43e-4a75-9269-9ea7bf9de261",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = UADETRACFrameGrabber()         \n",
    "fg.open_by_index(20)      \n",
    "# random access (DETRAC 1-based)\n",
    "idx, frame, path = fg.get_frame(10)\n",
    "idx , path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0337b-6fe9-460a-9096-384acb7b7322",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnotatedSequencePlayer:\n",
    "    def __init__(self, frame_grabber=None, base_path: Optional[Path]=None, monitor_resolution: Tuple[int,int]=(1000,2000)):\n",
    "        \"\"\"\n",
    "        Provide either a FrameGrabber instance or base_path (player will construct a FrameGrabber).\n",
    "        \"\"\"\n",
    "        if frame_grabber is not None:\n",
    "            self.grabber = frame_grabber\n",
    "        else:\n",
    "            from pathlib import Path as _P\n",
    "            from copy import deepcopy\n",
    "            # lazy import/construct FrameGrabber from caller scope\n",
    "            try:\n",
    "                FG = globals().get('FrameGrabber')\n",
    "                if FG is None:\n",
    "                    raise RuntimeError(\"FrameGrabber class not found in globals()\")\n",
    "                self.grabber = FG(base_path=Path(base_path) if base_path is not None else None)\n",
    "            except Exception as e:\n",
    "                raise RuntimeError(f\"Could not construct FrameGrabber: {e}\")\n",
    "        self.monitor_h, self.monitor_w = int(monitor_resolution[0]), int(monitor_resolution[1])\n",
    "\n",
    "    # --- geo annotate helper (same as before) ---\n",
    "    @staticmethod\n",
    "    def _to_int_pts(pts: Sequence[Sequence[float]]) -> np.ndarray:\n",
    "        arr = np.asarray(pts, dtype=float)\n",
    "        if arr.ndim == 1 and arr.size == 2:\n",
    "            arr = arr.reshape((1,2))\n",
    "        return arr.astype(np.int32)\n",
    "\n",
    "    def _geo_annotate_frame(self, frame: np.ndarray,\n",
    "                            roi: Optional[Sequence[Sequence[int]]]=None,\n",
    "                            line: Optional[Sequence[Sequence[int]]]=None,\n",
    "                            roi_color: Tuple[int,int,int]=(0,180,255),\n",
    "                            line_color: Tuple[int,int,int]=(0,0,255),\n",
    "                            roi_alpha: float=0.25, thickness: int=2) -> np.ndarray:\n",
    "        out = frame.copy()\n",
    "        h,w = out.shape[:2]\n",
    "        if roi:\n",
    "            pts = self._to_int_pts(roi); pts[:,0]=np.clip(pts[:,0],0,w-1); pts[:,1]=np.clip(pts[:,1],0,h-1)\n",
    "            overlay = out.copy(); cv2.fillPoly(overlay,[pts], color=roi_color)\n",
    "            cv2.addWeighted(overlay, roi_alpha, out, 1-roi_alpha, 0, out)\n",
    "            cv2.polylines(out,[pts], isClosed=True, color=roi_color, thickness=thickness)\n",
    "        if line and len(line) >= 2:\n",
    "            p = self._to_int_pts(line); p1=(int(p[0,0]),int(p[0,1])); p2=(int(p[1,0]),int(p[1,1]))\n",
    "            cv2.line(out,p1,p2,color=line_color,thickness=thickness,lineType=cv2.LINE_AA)\n",
    "            cv2.circle(out,p1,radius=max(3,thickness+1),color=line_color,thickness=-1)\n",
    "            cv2.circle(out,p2,radius=max(3,thickness+1),color=line_color,thickness=-1)\n",
    "        return out\n",
    "\n",
    "    # --- geometry lookup ---\n",
    "    def _find_geometry_for_sequence(self, geometry_df: Optional[pd.DataFrame], sequence: str):\n",
    "        if geometry_df is None:\n",
    "            return None, None\n",
    "        try:\n",
    "            mask = geometry_df['video'].astype(str).apply(lambda s: Path(s).stem == Path(sequence).stem)\n",
    "            if not mask.any():\n",
    "                return None, None\n",
    "            row = geometry_df.loc[mask].iloc[0]\n",
    "            roi = row.get(\"ROI\", None); line = row.get(\"line\", None)\n",
    "            if isinstance(roi, str): roi = ast.literal_eval(roi)\n",
    "            if isinstance(line, str): line = ast.literal_eval(line)\n",
    "            return roi, line\n",
    "        except Exception:\n",
    "            return None, None\n",
    "\n",
    "    def _has_sequence(self, df: pd.DataFrame, seq: str) -> bool:\n",
    "        try:\n",
    "            return seq in set(df['sequence'].astype(str).unique())\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    # --- core play using FrameGrabber ---\n",
    "    def play(self,\n",
    "             sequence: Optional[str]=None,\n",
    "             video_idx: Optional[int]=None,\n",
    "             annotations_df: Optional[pd.DataFrame]=None,\n",
    "             geometry_df: Optional[pd.DataFrame]=None,\n",
    "             play_fps: int = 25,\n",
    "             window_name: str = \"Annotated Sequence\",\n",
    "             save_path: Optional[Path] = None,\n",
    "             box_thickness: int = 2,\n",
    "             font_scale: float = 0.6,\n",
    "             scale: float = 1.0,\n",
    "             show_geometry: bool = True) -> Optional[Path]:\n",
    "\n",
    "        # open sequence via grabber (index or name)\n",
    "        if sequence is None and video_idx is not None:\n",
    "            self.grabber.open_by_index(video_idx)\n",
    "            sequence = self.grabber.sequence_dir.name\n",
    "        elif sequence is not None:\n",
    "            self.grabber.open_sequence(sequence)\n",
    "        else:\n",
    "            raise ValueError(\"Either sequence or video_idx must be provided.\")\n",
    "\n",
    "        # choose annotations df containing this sequence\n",
    "        if annotations_df is None:\n",
    "            raise FileNotFoundError(f\"Sequence '{sequence}' not found in provided annotations\")\n",
    "        \n",
    "        # geometry\n",
    "        roi, line = (None, None)\n",
    "        if show_geometry and geometry_df is not None:\n",
    "            roi, line = self._find_geometry_for_sequence(geometry_df, sequence)\n",
    "        if roi is None and line is None:\n",
    "            show_geometry = False\n",
    "\n",
    "        # prepare writer if requested (use first frame to get dims)\n",
    "        writer = None\n",
    "        if save_path is not None:\n",
    "            idx0, frame0, _ = self.grabber.get_frame(1)\n",
    "            h0,w0 = frame0.shape[:2]\n",
    "            w_out, h_out = int(w0 * scale), int(h0 * scale)\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            writer = cv2.VideoWriter(str(save_path), fourcc, play_fps, (w_out, h_out))\n",
    "\n",
    "        delay_ms = int(1000 / play_fps) if play_fps > 0 else 1\n",
    "        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "        try:\n",
    "            # iterate frames via grabber.frames() (1-based)\n",
    "            for idx, frame_bgr, path in self.grabber.frames(start=1):\n",
    "                # detection boxes -> user-provided functions in caller scope\n",
    "                rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "                anns = get_frame_annotations(sequence, idx)\n",
    "                annotated_rgb = annotate_image(rgb, anns, box_thickness=box_thickness, font_scale=font_scale)\n",
    "                annotated_bgr = cv2.cvtColor(annotated_rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                if show_geometry:\n",
    "                    annotated_bgr = self._geo_annotate_frame(annotated_bgr, roi=roi, line=line)\n",
    "\n",
    "                # scaling for display / writer\n",
    "                if scale != 1.0:\n",
    "                    new_w = int(annotated_bgr.shape[1] * scale)\n",
    "                    new_h = int(annotated_bgr.shape[0] * scale)\n",
    "                    annotated_disp = cv2.resize(annotated_bgr, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "                else:\n",
    "                    annotated_disp = annotated_bgr\n",
    "\n",
    "                cv2.imshow(window_name, annotated_disp)\n",
    "                if writer is not None:\n",
    "                    # writer should receive same sized frames as initialized (we wrote scaled dims)\n",
    "                    writer.write(annotated_disp)\n",
    "\n",
    "                key = cv2.waitKey(delay_ms) & 0xFF\n",
    "                if key in (ord('q'), 27):\n",
    "                    break\n",
    "        finally:\n",
    "            cv2.destroyAllWindows()\n",
    "            if writer is not None:\n",
    "                writer.release()\n",
    "\n",
    "        return Path(save_path) if save_path is not None else None\n",
    "\n",
    "    # convenience wrappers\n",
    "    def play_by_sequence(self, sequence: str, **kwargs) -> Optional[Path]:\n",
    "        return self.play(sequence=sequence, **kwargs)\n",
    "\n",
    "    def play_by_index(self, video_idx: int, **kwargs) -> Optional[Path]:\n",
    "        return self.play(video_idx=video_idx, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "# 1) create grabber (points to base folder containing sequences)\n",
    "fg = UADETRACFrameGrabber()\n",
    "\n",
    "# 2) create player that uses this grabber\n",
    "player = AnnotatedSequencePlayer(frame_grabber=fg)\n",
    "\n",
    "# 3) play by sequence name (live display; do not save)\n",
    "player.play_by_sequence(\n",
    "    \"MVI_39361\",\n",
    "    annotations_df=annotations_df,\n",
    "    geometry_df=geometry_df,\n",
    "    play_fps=24,\n",
    "    scale=0.8,\n",
    "    show_geometry=True,\n",
    "    save_path=None\n",
    ")\n",
    "\n",
    "# # 4) play by index (0-based): open the N-th folder under base\n",
    "# player.play_by_index(\n",
    "#     30,\n",
    "#     annotations_df=annotations_df,\n",
    "#     geometry_df=geometry_df,\n",
    "#     play_fps=40,\n",
    "#     scale=1.0,\n",
    "#     show_geometry=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30304f0-ec99-4e8f-a336-f08fd207191d",
   "metadata": {},
   "source": [
    "## Generate Counting Annotations For UA-DETRAC with respect to the geometric filtring applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a79e95b-c2f3-466e-a5b8-364b69017fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb89fc-620a-46d8-b40a-d758f0eff067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_frame_annotations(annotations_df: pd.DataFrame, sequence: str, frame: int) -> np.ndarray:\n",
    "#     # Filter rows for the given sequence and frame\n",
    "#     df = annotations_df[(annotations_df[\"sequence\"] == sequence) & (annotations_df[\"frame\"] == frame)]\n",
    "\n",
    "#     if df.empty:\n",
    "#         return np.zeros((0, 8), dtype=float)\n",
    "\n",
    "#     # Map categories to integer class IDs\n",
    "#     category_map = {\"car\": 0, \"van\": 1, \"others\": 2, \"bus\": 3}\n",
    "#     cls = df[\"category\"].map(category_map).fillna(-1).astype(int)\n",
    "\n",
    "#     # Build array: [x1, y1, x2, y2, id, conf, cls, ind]\n",
    "#     arr = np.stack([\n",
    "#         df[\"x1\"].values,\n",
    "#         df[\"y1\"].values,\n",
    "#         df[\"x2\"].values,\n",
    "#         df[\"y2\"].values,\n",
    "#         df[\"video_track_id\"].values,\n",
    "#         np.ones(len(df)),     # conf = 1.0\n",
    "#         cls.values,\n",
    "#         np.zeros(len(df))     # ind = 0\n",
    "#     ], axis=1)\n",
    "\n",
    "#     return arr.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d0e19-bfc9-49e4-a192-177d17767641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence = \"MVI_39031\"\n",
    "# frame = 1000\n",
    "\n",
    "# res = get_frame_annotations(annotations_df , sequence, frame)\n",
    "# res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e873be-9f76-4aaf-b025-e772c7ae2b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_logics = dict()\n",
    "# logics = [[\"by_id\"] , [\"by_cross_id\"] , [\"by_id\" , \"by_vicinity\"] , [\"by_cross_id\" , \"by_vicinity\"]  , [\"by_cross_id\" , \"by_id\" , \"by_vicinity\"]]\n",
    "# for i , logic in enumerate(logics):\n",
    "#     map_logics[f\"Method_{i+1}\"] = logic\n",
    "# map_logics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109ac53-62fe-4e9f-b016-aa8a9e8c65d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from counting.count_config_loader import CountingConfigLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194081c6-a447-4348-b722-7edd0bb8b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter_load = CountingConfigLoader(frame_size = 900)\n",
    "\n",
    "# cfg = counter_load._read_yaml(counter_load.config_path)\n",
    "# rois_raw = cfg.get(\"rois\") or []\n",
    "# global_raw = cfg.get(\"global\") or None\n",
    "# roi = rois_raw[0]          # [\"by_cross_id\" , \"by_id\" , \"by_vicinity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4063bf0-97e9-4fb6-98d3-fedea0030591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting_logic , polygon , line , line_vicinity = [\"by_id\"] , geometry_df[\"ROI\"][0] , geometry_df[\"line\"][0] , 0.15\n",
    "# roi[\"counting_logic\"] , roi[\"polygon\"] , roi[\"line\"] , roi[\"line_vicinity\"] = counting_logic , polygon , line , line_vicinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8845ddb5-2329-4be4-ad92-58415b59d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = counter_load._normalize_roi(roi , 0)\n",
    "# counter.line_vicinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54526372-aec1-413f-b9a3-a6a188e7b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import copy\n",
    "# import logging\n",
    "# from pathlib import Path\n",
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# from datetime import datetime\n",
    "\n",
    "# from framegrabber.frame_grabber import UADETRACFrameGrabber\n",
    "# from counting.count_config_loader import CountingConfigLoader\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# base_path = Path(r\"C:\\Users\\hamza\\Datasets\\TrafficDatasets\\UA_DETRAC_Original\")\n",
    "\n",
    "# save_path = Path(\"uadetrac_dataset/ua_detrac_annotations.csv\")\n",
    "# annotations_df = pd.read_csv(save_path)\n",
    "\n",
    "# save_path = Path(\"uadetrac_dataset/uadetrac_vid_roi_ann.csv\")\n",
    "# geometry_df = pd.read_csv(save_path, converters={\"ROI\": eval, \"line\": eval})\n",
    "\n",
    "\n",
    "# # reduce noisy warnings (adjust as needed)\n",
    "# logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "# # ---------- Config / I/O ----------\n",
    "# RESULTS_DIR = Path(\"uadetrac_dataset__\")\n",
    "# RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# RESULTS_FILE = RESULTS_DIR / \"uadetrac_geo_counts_all.json\"\n",
    "\n",
    "# LINE_VICINITY = 0.15\n",
    "# FPS = 25\n",
    "\n",
    "# # class map and counting map required by your spec\n",
    "# CLASS_MAP = {\"car\": 0, \"van\": 1, \"others\": 2, \"bus\": 3}\n",
    "# COUNTING_MAP = {\n",
    "#     \"counter_1\": [\"by_id\"],\n",
    "#     \"counter_2\": [\"by_cross_id\"],\n",
    "#     \"counter_3\": [\"by_id\", \"by_vicinity\"],\n",
    "#     \"counter_4\": [\"by_cross_id\", \"by_vicinity\"],\n",
    "#     \"counter_5\": [\"by_cross_id\", \"by_id\", \"by_vicinity\"],\n",
    "# }\n",
    "\n",
    "# # sequences to process (from annotations_df)\n",
    "# sequences = list(annotations_df[\"sequence\"].unique())\n",
    "# counter_load = CountingConfigLoader(frame_size = 900)\n",
    "\n",
    "\n",
    "# def get_frame_annotations(annotations_df: pd.DataFrame, sequence: str, frame: int) -> np.ndarray:\n",
    "#     # Filter rows for the given sequence and frame\n",
    "#     df = annotations_df[(annotations_df[\"sequence\"] == sequence) & (annotations_df[\"frame\"] == frame)]\n",
    "\n",
    "#     if df.empty:\n",
    "#         return np.zeros((0, 8), dtype=float)\n",
    "\n",
    "#     # Map categories to integer class IDs\n",
    "#     category_map = {\"car\": 0, \"van\": 1, \"others\": 2, \"bus\": 3}\n",
    "#     cls = df[\"category\"].map(category_map).fillna(-1).astype(int)\n",
    "\n",
    "#     # Build array: [x1, y1, x2, y2, id, conf, cls, ind]\n",
    "#     arr = np.stack([\n",
    "#         df[\"x1\"].values,\n",
    "#         df[\"y1\"].values,\n",
    "#         df[\"x2\"].values,\n",
    "#         df[\"y2\"].values,\n",
    "#         df[\"video_track_id\"].values,\n",
    "#         np.ones(len(df)),     # conf = 1.0\n",
    "#         cls.values,\n",
    "#         np.zeros(len(df))     # ind = 0\n",
    "#     ], axis=1)\n",
    "\n",
    "#     return arr.astype(float)\n",
    "\n",
    "# # ---------- helpers ----------\n",
    "# def _make_prev_bycls(counter):\n",
    "#     arr = getattr(counter.count_result, \"counts_by_class\", None)\n",
    "#     if isinstance(arr, np.ndarray) and arr.size > 0:\n",
    "#         return arr.copy().astype(int)\n",
    "#     if arr is None:\n",
    "#         return np.zeros(0, dtype=int)\n",
    "#     return np.asarray(arr, dtype=int).copy()\n",
    "\n",
    "# def _safe_get_split_for_sequence(annotations_df, sequence):\n",
    "#     try:\n",
    "#         mask = annotations_df['sequence'].astype(str) == str(sequence)\n",
    "#         if mask.any() and 'split' in annotations_df.columns:\n",
    "#             return str(annotations_df.loc[mask, 'split'].iloc[0])\n",
    "#     except Exception:\n",
    "#         pass\n",
    "#     return \"unknown\"\n",
    "\n",
    "# def _load_or_init_results(path: Path):\n",
    "#     if path.exists():\n",
    "#         try:\n",
    "#             with path.open(\"r\", encoding=\"utf-8\") as fh:\n",
    "#                 return json.load(fh)\n",
    "#         except Exception:\n",
    "#             # corrupt or unreadable -> start fresh but keep a backup\n",
    "#             backup = path.with_suffix(\".broken.json\")\n",
    "#             path.rename(backup)\n",
    "#             return {\"meta\": {}, \"sequences\": {}}\n",
    "#     return {\"meta\": {}, \"sequences\": {}}\n",
    "\n",
    "# def _atomic_write_json(path: Path, data):\n",
    "#     tmp = path.with_suffix(\".tmp.json\")\n",
    "#     with tmp.open(\"w\", encoding=\"utf-8\") as fh:\n",
    "#         json.dump(data, fh, ensure_ascii=False, indent=2)\n",
    "#     tmp.replace(path)\n",
    "\n",
    "# # ---------- prepare top-level file (may be updated later) ----------\n",
    "# all_results = _load_or_init_results(RESULTS_FILE)\n",
    "\n",
    "# # create meta if missing / update timestamp\n",
    "# all_results[\"meta\"] = {\n",
    "#     \"tool\": \"UA-Detrac GeoCount GT\",\n",
    "#     \"version\": \"1.0\",\n",
    "#     \"timestamp_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "#     \"fps\": FPS,\n",
    "#     \"class_map\": CLASS_MAP,\n",
    "#     \"counting_map\": COUNTING_MAP,\n",
    "#     \"description\": (\n",
    "#         \"Per-sequence geometric counting ground-truth for the UA-DETRAC dataset: \"\n",
    "#         \"stores ROI/line parameters and per-logic totals, per-class breakdowns \"\n",
    "#         \"(optional per-frame counts), plus timing metadata — contains results for ALL videos \"\n",
    "#         \"(sequences); intended as reproducible ground truth for benchmarking AI vision–based vehicle counting systems.\"\n",
    "#     )\n",
    "# }\n",
    "# if \"sequences\" not in all_results:\n",
    "#     all_results[\"sequences\"] = {}\n",
    "\n",
    "# # ---------- main loop (sequences) ----------\n",
    "# seq_pbar = tqdm(sequences, desc=\"Sequences\", unit=\"seq\")\n",
    "# for sequence in seq_pbar:\n",
    "#     # skip sequence if already present (checkpoint)\n",
    "#     if str(sequence) in all_results[\"sequences\"]:\n",
    "#         seq_pbar.set_postfix_str(f\"{sequence} (skipped)\")\n",
    "#         continue\n",
    "\n",
    "#     # prepare frame grabber for this sequence\n",
    "#     fg = UADETRACFrameGrabber()             # use your FrameGrabber\n",
    "#     try:\n",
    "#         fg.open_sequence(sequence)\n",
    "#     except Exception as e:\n",
    "#         logging.warning(f\"Could not open sequence {sequence}: {e}\")\n",
    "#         # record failure entry and continue\n",
    "#         all_results[\"sequences\"][str(sequence)] = {\n",
    "#             \"split\": _safe_get_split_for_sequence(annotations_df, sequence),\n",
    "#             \"num_frames\": 0,\n",
    "#             \"roi\": None,\n",
    "#             \"line\": None,\n",
    "#             \"line_vicinity\": LINE_VICINITY,\n",
    "#             \"by_logic\": {},\n",
    "#             \"error\": str(e)\n",
    "#         }\n",
    "#         _atomic_write_json(RESULTS_FILE, all_results)\n",
    "#         continue\n",
    "\n",
    "#     # geometry lookup by stem match\n",
    "#     geom_mask = geometry_df['video'].astype(str).apply(lambda s: Path(s).stem == Path(sequence).stem)\n",
    "#     if geom_mask.any():\n",
    "#         geom_row = geometry_df.loc[geom_mask].iloc[0]\n",
    "#         polygon = geom_row.get(\"ROI\", None)\n",
    "#         line = geom_row.get(\"line\", None)\n",
    "#     else:\n",
    "#         polygon, line = None, None\n",
    "\n",
    "#     # instantiate counters according to COUNTING_MAP\n",
    "#     counters = {}\n",
    "#     for i, (cname, logic_list) in enumerate(COUNTING_MAP.items(), start=1):\n",
    "#         roi_template = {\n",
    "#             \"name\": cname,\n",
    "#             \"enable\": True,\n",
    "#             \"polygon\": polygon,\n",
    "#             \"box_in_polygon_mode\": \"center_in_polygon\",\n",
    "#             \"line\": line,\n",
    "#             \"line_vicinity\": LINE_VICINITY,\n",
    "#             \"counting_logic\": logic_list\n",
    "#         }\n",
    "#         counters[cname] = counter_load._normalize_roi(copy.deepcopy(roi_template), 0)\n",
    "\n",
    "#     # initial cumulative state\n",
    "#     prev_totals = {name: int(getattr(c.count_result, \"total_count\", 0)) for name, c in counters.items()}\n",
    "#     prev_bycls = {name: _make_prev_bycls(c) for name, c in counters.items()}\n",
    "\n",
    "#     # per-frame storage\n",
    "#     per_frame_store = {name: {\"total\": [], \"by_class\": [], \"timing_sec\": []} for name in counters}\n",
    "\n",
    "#     # process frames (no inner tqdm to keep console compact)\n",
    "#     for frame_idx, frame_bgr, frame_path in fg.frames(start=1):\n",
    "#         # get annotations for this frame (your function must exist in scope)\n",
    "#         anns = get_frame_annotations(annotations_df, sequence, frame_idx)\n",
    "\n",
    "#         for name, counter in counters.items():\n",
    "#             t0 = time.perf_counter()\n",
    "#             result = counter.count(anns)\n",
    "#             t1 = time.perf_counter()\n",
    "\n",
    "#             frame_time = float(t1 - t0)\n",
    "#             curr_total = int(getattr(result, \"total_count\", 0))\n",
    "#             curr_bycls = getattr(result, \"counts_by_class\", None)\n",
    "#             curr_bycls = np.asarray(curr_bycls, dtype=int) if curr_bycls is not None else np.zeros(0, dtype=int)\n",
    "\n",
    "#             # align lengths and get per-frame increments\n",
    "#             max_len = max(prev_bycls[name].size, curr_bycls.size)\n",
    "#             if max_len == 0:\n",
    "#                 per_frame_by_class = []\n",
    "#                 prev_bycls[name] = np.zeros(0, dtype=int)\n",
    "#             else:\n",
    "#                 prev_pad = np.pad(prev_bycls[name], (0, max_len - prev_bycls[name].size), mode='constant')\n",
    "#                 curr_pad = np.pad(curr_bycls, (0, max_len - curr_bycls.size), mode='constant')\n",
    "#                 per_frame_by_class = (curr_pad - prev_pad).tolist()\n",
    "#                 prev_bycls[name] = curr_pad.copy()\n",
    "\n",
    "#             per_frame_total = curr_total - prev_totals.get(name, 0)\n",
    "#             prev_totals[name] = curr_total\n",
    "\n",
    "#             per_frame_store[name][\"total\"].append(int(per_frame_total))\n",
    "#             per_frame_store[name][\"by_class\"].append(per_frame_by_class)\n",
    "#             per_frame_store[name][\"timing_sec\"].append(frame_time)\n",
    "\n",
    "#         # update single progress bar postfix\n",
    "#         seq_pbar.set_postfix_str(f\"{sequence} {frame_idx}/{fg.frame_count}\")\n",
    "\n",
    "#     # build sequence entry (video-level metadata stored here)\n",
    "#     seq_entry = {\n",
    "#         \"split\": _safe_get_split_for_sequence(annotations_df, sequence),\n",
    "#         \"num_frames\": int(fg.frame_count),\n",
    "#         \"roi\": polygon,\n",
    "#         \"line\": line,\n",
    "#         \"line_vicinity\": LINE_VICINITY,\n",
    "#         \"by_logic\": {}\n",
    "#     }\n",
    "\n",
    "#     # populate by_logic results\n",
    "#     for name in counters:\n",
    "#         times = per_frame_store[name][\"timing_sec\"]\n",
    "#         seq_entry[\"by_logic\"][name] = {\n",
    "#             \"total_count\": int(prev_totals.get(name, 0)),\n",
    "#             \"counts_by_class\": prev_bycls[name].tolist() if isinstance(prev_bycls[name], np.ndarray) else [],\n",
    "#             \"per_frame_counts\": per_frame_store[name][\"total\"],\n",
    "#             \"per_frame_counts_by_class\": per_frame_store[name][\"by_class\"],\n",
    "#             \"per_frame_timing_sec\": per_frame_store[name][\"timing_sec\"],\n",
    "#             \"total_time_sec\": float(sum(times)),\n",
    "#             \"avg_time_sec\": float(np.mean(times)) if times else 0.0,\n",
    "#         }\n",
    "\n",
    "#     # insert into global results and checkpoint write\n",
    "#     all_results[\"sequences\"][str(sequence)] = seq_entry\n",
    "#     # update meta timestamp\n",
    "#     all_results[\"meta\"][\"timestamp_utc\"] = datetime.utcnow().isoformat() + \"Z\"\n",
    "#     _atomic_write_json(RESULTS_FILE, all_results)\n",
    "\n",
    "# seq_pbar.close()\n",
    "# print(f\"Saved overall results to: {RESULTS_FILE.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89144143-1fc3-41c2-939a-4af93070e1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca675c-722e-4342-856e-5ddb9e4243e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d4978a-3e34-4ccf-b572-75a94c55826d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2cce5b-2aca-4e58-9e2f-87292d896650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e137a6-5a17-4f6f-acb6-4793f68dc081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb0f3a9-dd43-4349-b8f5-10c529e7bcd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df755344-af0d-4403-9c46-4fb622c2c498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45f9ea-4980-47b1-a7d9-e8650ed7e19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff36d0e7-73c6-4636-9db5-a6eacc407aec",
   "metadata": {},
   "source": [
    "## Running vehicle counting algorithms on UADETRAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed110d00-7cd0-43a1-9830-bbbe51a1c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c7a326-b914-4656-a172-5a5c0fbfa8a8",
   "metadata": {},
   "source": [
    "Make sure you are in the working directory: \n",
    "* Road_Traffic_Monitoring_AI_Vision_Based_SMART_sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d26572-31a0-4314-a5c7-c4d31957e504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c134572-445a-45ca-94b5-030dfffe07f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79db494-8cab-48ea-bc94-70db18670ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uadetrac_geo_count_pipeline.py\n",
    "import json\n",
    "import copy\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# local packages (make sure these module paths are correct in your environment)\n",
    "from framegrabber.frame_grabber import UADETRACFrameGrabber\n",
    "from detection.ultralytics_detectors import UltralyticsDetector\n",
    "from tracking.track import Tracker\n",
    "from counting.count_config_loader import CountingConfigLoader\n",
    "from utils.profilers import Profile\n",
    "\n",
    "# -----------------------\n",
    "# Configuration / I/O\n",
    "# -----------------------\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "\n",
    "BASE_PATH = Path(r\"C:\\Users\\hamza\\Datasets\\TrafficDatasets\\UA_DETRAC_Original\")\n",
    "\n",
    "ANNOTATIONS_CSV = Path(\"uadetrac_dataset/ua_detrac_annotations.csv\")\n",
    "GEOMETRY_CSV = Path(\"uadetrac_dataset/uadetrac_vid_roi_ann.csv\")\n",
    "\n",
    "annotations_df = pd.read_csv(ANNOTATIONS_CSV)\n",
    "geometry_df = pd.read_csv(GEOMETRY_CSV, converters={\"ROI\": eval, \"line\": eval})\n",
    "\n",
    "RESULTS_DIR = Path(\"uadetrac_dataset\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_FILE = RESULTS_DIR / \"uadetrac_yolov8_ocsort_geo_counts.json\"\n",
    "\n",
    "# per-sequence random vicinities (example)\n",
    "TRACKLESS_VICINITY = np.random.uniform(0.01, 0.04, size=100)\n",
    "TRACK_VICINITY = np.random.uniform(0.1, 0.15, size=100)\n",
    "\n",
    "FPS = 25\n",
    "\n",
    "# class map (used in meta)\n",
    "CLASS_MAP = {\n",
    "    1: \"bicycle\",\n",
    "    2: \"car\",\n",
    "    3: \"motorcycle\",\n",
    "    5: \"bus\",\n",
    "    7: \"truck\",\n",
    "}\n",
    "\n",
    "# counting logics (fixed)\n",
    "COUNTING_MAP = {\n",
    "    \"counter_0\": [\"by_vicinity\"],\n",
    "    \"counter_1\": [\"by_id\"],\n",
    "    \"counter_2\": [\"by_cross_id\"],\n",
    "    \"counter_3\": [\"by_id\", \"by_vicinity\"],\n",
    "    \"counter_4\": [\"by_cross_id\", \"by_vicinity\"],\n",
    "    \"counter_5\": [\"by_cross_id\", \"by_id\", \"by_vicinity\"],\n",
    "}\n",
    "\n",
    "# sequences from annotations\n",
    "sequences = list(annotations_df[\"sequence\"].unique())\n",
    "counter_load = CountingConfigLoader(frame_size=900)\n",
    "\n",
    "# -----------------------\n",
    "# Instantiate detector & tracker (adjust args as needed)\n",
    "# -----------------------\n",
    "# NOTE: you must ensure UltralyticsDetector and Tracker constructors below\n",
    "# match your actual classes / arguments.\n",
    "my_model = UltralyticsDetector(\"yolov8n.pt\", conf=0.1)     # <-- ensure this API exists\n",
    "tracker = Tracker(\"ocsort\")                                 # <-- replace args to match your Tracker\n",
    "\n",
    "# device extraction (robust)\n",
    "try:\n",
    "    device = my_model.predictor.device\n",
    "except Exception:\n",
    "    device = getattr(my_model, \"device\", None)\n",
    "\n",
    "# pipeline metadata (store detector/tracker config in global meta)\n",
    "pipeline_meta = {\n",
    "    \"detector\": {\n",
    "        \"name\": getattr(my_model, \"name\", \"yolov8n\"),\n",
    "        \"repo\": \"https://github.com/ultralytics/ultralytics\",\n",
    "        \"input_size\": getattr(my_model, \"input_size\", None),\n",
    "        \"conf_thresh\": getattr(my_model, \"conf_threshold\", getattr(my_model, \"conf\", None)),\n",
    "        \"nms_iou\": getattr(my_model, \"nms_iou\", None),\n",
    "    },\n",
    "    \"tracker\": {\n",
    "        \"name\": getattr(tracker, \"name\", \"ocsort\"),\n",
    "        \"repo\": \"https://github.com/ifzhang/ByteTrack-or-BoxMot\",\n",
    "        \"params\": getattr(tracker, \"params\", {}),\n",
    "    }\n",
    "}\n",
    "\n",
    "# -----------------------\n",
    "# Profiling helpers\n",
    "# -----------------------\n",
    "def create_profile_map(device=None):\n",
    "    \"\"\"Create per-sequence fresh Profile objects for pipeline stages + counters.\"\"\"\n",
    "    profile_map = {}\n",
    "    # device-specific profiles\n",
    "    for name in (\"pre\", \"inf\", \"post\"):\n",
    "        profile_map[name] = Profile(device=device) if device is not None else Profile()\n",
    "    # tracking + counters\n",
    "    profile_map[\"track\"] = Profile()\n",
    "    for i in range(6):  # counter_0 .. counter_5\n",
    "        profile_map[f\"counter_{i}\"] = Profile()\n",
    "    return profile_map\n",
    "\n",
    "# helpers for counts\n",
    "def _make_prev_bycls(counter):\n",
    "    arr = getattr(counter.count_result, \"counts_by_class\", None)\n",
    "    if isinstance(arr, np.ndarray) and arr.size > 0:\n",
    "        return arr.copy().astype(int)\n",
    "    if arr is None:\n",
    "        return np.zeros(0, dtype=int)\n",
    "    return np.asarray(arr, dtype=int).copy()\n",
    "\n",
    "def _safe_get_split_for_sequence(annotations_df, sequence):\n",
    "    try:\n",
    "        mask = annotations_df['sequence'].astype(str) == str(sequence)\n",
    "        if mask.any() and 'split' in annotations_df.columns:\n",
    "            return str(annotations_df.loc[mask, 'split'].iloc[0])\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"unknown\"\n",
    "\n",
    "def _load_or_init_results(path: Path):\n",
    "    if path.exists():\n",
    "        try:\n",
    "            with path.open(\"r\", encoding=\"utf-8\") as fh:\n",
    "                return json.load(fh)\n",
    "        except Exception:\n",
    "            backup = path.with_suffix(\".broken.json\")\n",
    "            path.rename(backup)\n",
    "            return {\"meta\": {}, \"sequences\": {}}\n",
    "    return {\"meta\": {}, \"sequences\": {}}\n",
    "\n",
    "def _atomic_write_json(path: Path, data):\n",
    "    tmp = path.with_suffix(\".tmp.json\")\n",
    "    with tmp.open(\"w\", encoding=\"utf-8\") as fh:\n",
    "        json.dump(data, fh, ensure_ascii=False, indent=2)\n",
    "    tmp.replace(path)\n",
    "\n",
    "# -----------------------\n",
    "# Prepare top-level results file\n",
    "# -----------------------\n",
    "all_results = _load_or_init_results(RESULTS_FILE)\n",
    "all_results[\"meta\"] = {\n",
    "    \"tool\": \"UA-Detrac GeoCount GT\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"timestamp_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"fps\": FPS,\n",
    "    \"class_map\": CLASS_MAP,\n",
    "    \"counting_map\": COUNTING_MAP,\n",
    "    \"pipeline\": pipeline_meta,\n",
    "    \"description\": (\n",
    "        \"Experiment results for a fixed detector+tracker vehicle-counting pipeline on the UA-DETRAC dataset. \"\n",
    "        \"For each video (sequence) this file stores ROI/line parameters, per-logic counting totals and per-class breakdowns, \"\n",
    "        \"separated per-frame timing arrays for pipeline stages (pre/inference/post/track) and per-counter timings. \"\n",
    "        \"Intended for performance and accuracy benchmarking of counting systems.\"\n",
    "    )\n",
    "}\n",
    "if \"sequences\" not in all_results:\n",
    "    all_results[\"sequences\"] = {}\n",
    "\n",
    "# -----------------------\n",
    "# Main loop: process sequences\n",
    "# -----------------------\n",
    "seq_pbar = tqdm(sequences, desc=\"Sequences\", unit=\"seq\")\n",
    "for seq_idx, sequence in enumerate(seq_pbar):\n",
    "    seq_key = str(sequence)\n",
    "    if seq_key in all_results[\"sequences\"]:\n",
    "        seq_pbar.set_postfix_str(f\"{sequence} (skipped)\")\n",
    "        continue\n",
    "\n",
    "    # per-sequence vicinities\n",
    "    track_vicinity = float(TRACK_VICINITY[seq_idx])\n",
    "    trackless_vicinity = float(TRACKLESS_VICINITY[seq_idx])\n",
    "\n",
    "    # open frames\n",
    "    fg = UADETRACFrameGrabber()\n",
    "    try:\n",
    "        fg.open_sequence(sequence)\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Could not open sequence {sequence}: {e}\")\n",
    "        all_results[\"sequences\"][seq_key] = {\n",
    "            \"split\": _safe_get_split_for_sequence(annotations_df, sequence),\n",
    "            \"num_frames\": 0,\n",
    "            \"roi\": None,\n",
    "            \"line\": None,\n",
    "            \"line_vicinity\": {\"track\": None, \"trackless\": None},\n",
    "            \"by_logic\": {},\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "        _atomic_write_json(RESULTS_FILE, all_results)\n",
    "        continue\n",
    "\n",
    "    # geometry lookup\n",
    "    geom_mask = geometry_df['video'].astype(str).apply(lambda s: Path(s).stem == Path(sequence).stem)\n",
    "    if geom_mask.any():\n",
    "        geom_row = geometry_df.loc[geom_mask].iloc[0]\n",
    "        polygon = geom_row.get(\"ROI\", None)\n",
    "        line = geom_row.get(\"line\", None)\n",
    "    else:\n",
    "        polygon, line = None, None\n",
    "\n",
    "    # instantiate counters\n",
    "    counters = {}\n",
    "    for cname, logic_list in COUNTING_MAP.items():\n",
    "        lv = trackless_vicinity if cname == \"counter_0\" else track_vicinity\n",
    "        roi_template = {\n",
    "            \"name\": cname,\n",
    "            \"enable\": True,\n",
    "            \"polygon\": polygon,\n",
    "            \"box_in_polygon_mode\": \"center_in_polygon\",\n",
    "            \"line\": line,\n",
    "            \"line_vicinity\": lv,\n",
    "            \"counting_logic\": logic_list\n",
    "        }\n",
    "        counters[cname] = counter_load._normalize_roi(copy.deepcopy(roi_template), 0)\n",
    "\n",
    "    # fresh profiles for this sequence\n",
    "    PROFILE_MAP = create_profile_map(device=device)\n",
    "\n",
    "    # per-frame stores\n",
    "    per_frame_pipeline_timing = {\n",
    "        \"pre\": [], \"inf\": [], \"post\": [], \"track\": [], \"counters\": {name: [] for name in counters}\n",
    "    }\n",
    "    per_frame_counts_by_logic = {name: {\"total\": [], \"by_class\": []} for name in counters}\n",
    "\n",
    "    # cumulative state\n",
    "    prev_totals = {name: int(getattr(c.count_result, \"total_count\", 0)) for name, c in counters.items()}\n",
    "    prev_bycls = {name: _make_prev_bycls(c) for name, c in counters.items()}\n",
    "\n",
    "    # frame loop\n",
    "    with torch.inference_mode():\n",
    "        for frame_idx, frame_data, frame_path in fg.frames(start=1):\n",
    "            if frame_data is None:\n",
    "                continue\n",
    "\n",
    "            # detector: pre -> inf -> post\n",
    "            with PROFILE_MAP[\"pre\"]:\n",
    "                pre_input = my_model.preprocess(frame_data)\n",
    "            per_frame_pipeline_timing[\"pre\"].append(float(PROFILE_MAP[\"pre\"].dt))\n",
    "\n",
    "            with PROFILE_MAP[\"inf\"]:\n",
    "                raw_out = my_model.infer(pre_input)\n",
    "            per_frame_pipeline_timing[\"inf\"].append(float(PROFILE_MAP[\"inf\"].dt))\n",
    "\n",
    "            with PROFILE_MAP[\"post\"]:\n",
    "                ready_to_track = my_model.postprocess(raw_out, pre_input, frame_data)\n",
    "            per_frame_pipeline_timing[\"post\"].append(float(PROFILE_MAP[\"post\"].dt))\n",
    "\n",
    "            # tracking\n",
    "            with PROFILE_MAP[\"track\"]:\n",
    "                tracks = tracker.update(ready_to_track, frame_data)\n",
    "            per_frame_pipeline_timing[\"track\"].append(float(PROFILE_MAP[\"track\"].dt))\n",
    "\n",
    "            # counters (time each)\n",
    "            for name, counter in counters.items():\n",
    "                with PROFILE_MAP[name]:\n",
    "                    res = counter.count(tracks)\n",
    "                per_frame_pipeline_timing[\"counters\"][name].append(float(PROFILE_MAP[name].dt))\n",
    "\n",
    "                # compute per-frame increments (safe padding)\n",
    "                curr_total = int(getattr(res, \"total_count\", 0))\n",
    "                curr_bycls = getattr(res, \"counts_by_class\", None)\n",
    "                curr_bycls = np.asarray(curr_bycls, dtype=int) if curr_bycls is not None else np.zeros(0, dtype=int)\n",
    "\n",
    "                max_len = max(prev_bycls[name].size, curr_bycls.size)\n",
    "                if max_len == 0:\n",
    "                    per_frame_by_class = []\n",
    "                    prev_bycls[name] = np.zeros(0, dtype=int)\n",
    "                else:\n",
    "                    prev_pad = np.pad(prev_bycls[name], (0, max_len - prev_bycls[name].size), mode='constant')\n",
    "                    curr_pad = np.pad(curr_bycls, (0, max_len - curr_bycls.size), mode='constant')\n",
    "                    per_frame_by_class = (curr_pad - prev_pad).tolist()\n",
    "                    prev_bycls[name] = curr_pad.copy()\n",
    "\n",
    "                per_frame_total = curr_total - prev_totals.get(name, 0)\n",
    "                prev_totals[name] = curr_total\n",
    "\n",
    "                per_frame_counts_by_logic[name][\"total\"].append(int(per_frame_total))\n",
    "                per_frame_counts_by_logic[name][\"by_class\"].append(per_frame_by_class)\n",
    "\n",
    "            # update progress postfix\n",
    "            seq_pbar.set_postfix_str(f\"{sequence} {frame_idx}/{fg.frame_count}\")\n",
    "\n",
    "    # build timing summary\n",
    "    timing_summary = {\n",
    "        \"pre_total_sec\": float(PROFILE_MAP[\"pre\"].t),\n",
    "        \"inf_total_sec\": float(PROFILE_MAP[\"inf\"].t),\n",
    "        \"post_total_sec\": float(PROFILE_MAP[\"post\"].t),\n",
    "        \"track_total_sec\": float(PROFILE_MAP[\"track\"].t),\n",
    "        \"counters_total_sec\": {name: float(PROFILE_MAP[name].t) for name in counters}\n",
    "    }\n",
    "\n",
    "    # assemble sequence entry\n",
    "    seq_entry = {\n",
    "        \"split\": _safe_get_split_for_sequence(annotations_df, sequence),\n",
    "        \"num_frames\": int(fg.frame_count),\n",
    "        \"roi\": polygon,\n",
    "        \"line\": line,\n",
    "        \"line_vicinity\": {\"track\": track_vicinity, \"trackless\": trackless_vicinity},\n",
    "        \"timing_summary\": timing_summary,\n",
    "        \"per_frame_pipeline_timing\": per_frame_pipeline_timing,\n",
    "        \"by_logic\": {}\n",
    "    }\n",
    "\n",
    "    for name in counters:\n",
    "        seq_entry[\"by_logic\"][name] = {\n",
    "            \"total_count\": int(prev_totals.get(name, 0)),\n",
    "            \"counts_by_class\": prev_bycls[name].tolist() if isinstance(prev_bycls[name], np.ndarray) else [],\n",
    "            \"per_frame_counts\": per_frame_counts_by_logic[name][\"total\"],\n",
    "            \"per_frame_counts_by_class\": per_frame_counts_by_logic[name][\"by_class\"]\n",
    "        }\n",
    "\n",
    "    # checkpoint save\n",
    "    all_results[\"sequences\"][seq_key] = seq_entry\n",
    "    all_results[\"meta\"][\"timestamp_utc\"] = datetime.utcnow().isoformat() + \"Z\"\n",
    "    _atomic_write_json(RESULTS_FILE, all_results)\n",
    "\n",
    "seq_pbar.close()\n",
    "print(f\"Saved overall results to: {RESULTS_FILE.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e874cfb-4e04-4a56-8999-c3115bfd5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a6cbb8-b898-44c0-b606-2a8a5e482e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3970c28-4248-415a-9ce1-9a1641982e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c67dc2-4538-4350-af88-fb8ba11911ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074174e1-a89c-4327-b9ab-31598f301e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "from framegrabber.frame_grabber import FrameGrabber\n",
    "\n",
    "from detection.ultralytics_detectors import UltralyticsDetector\n",
    "\n",
    "from tracking.track import Tracker\n",
    "\n",
    "from counting.count_config_loader import CountingConfigLoader\n",
    "from counting.count_visualizer import CountVisualizer\n",
    "\n",
    "from framegrabber.frame_grabber import UADETRACFrameGrabber\n",
    "#####################################################################################################################################\n",
    "\n",
    "my_model = UltralyticsDetector(\"yolov8n.pt\" , conf=0.1)         # \"rtdetr-l.pt\"  , \"yolov8n.pt\"\n",
    "coco_vehicles = [1, 2, 3, 5, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4557637-f9a4-4aab-8092-094053aebb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = my_model.predictor.device\n",
    "from ultralytics.utils import ops\n",
    "profile = ops.Profile(device=device)\n",
    "profile.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30bbcf-aa34-4503-a625-04c10baea13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_load = CountingConfigLoader(frame_size = 900)\n",
    "\n",
    "cfg = counter_load._read_yaml(counter_load.config_path)\n",
    "rois_raw = cfg.get(\"rois\") or []\n",
    "global_raw = cfg.get(\"global\") or None\n",
    "roi = rois_raw[0]          # [\"by_cross_id\" , \"by_id\" , \"by_vicinity\"]\n",
    "\n",
    "roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ad6932-0361-460c-b228-4e58b49ba9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "counting_logic , polygon , line , line_vicinity = [\"by_id\"] , geometry_df[\"ROI\"][0] , geometry_df[\"line\"][0] , 0.15\n",
    "roi[\"counting_logic\"] , roi[\"polygon\"] , roi[\"line\"] , roi[\"line_vicinity\"] = counting_logic , polygon , line , line_vicinity\n",
    "roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2c8cf-3f61-40ca-a0f6-a24e2c0ed5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = counter_load._normalize_roi(roi , 0)\n",
    "counter.line_vicinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a053a7-3963-45ca-9f5e-9c44d64d5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb682ba-ea25-4daa-af54-f4b2ff149405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _make_prev_bycls(counter):\n",
    "    arr = getattr(counter.count_result, \"counts_by_class\", None)\n",
    "    if isinstance(arr, np.ndarray) and arr.size > 0:\n",
    "        return arr.copy().astype(int)\n",
    "    if arr is None:\n",
    "        return np.zeros(0, dtype=int)\n",
    "    return np.asarray(arr, dtype=int).copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "device = my_model.predictor.device\n",
    "\n",
    "inf_profile = Profile(device=device)\n",
    "pre_profile = Profile(device=device)\n",
    "post_profile = Profile(device=device)\n",
    "\n",
    "track_profile = Profile()\n",
    "\n",
    "counter_0_profile = Profile()\n",
    "counter_1_profile = Profile()\n",
    "counter_2_profile = Profile()\n",
    "counter_3_profile = Profile()\n",
    "counter_4_profile = Profile()\n",
    "counter_5_profile = Profile()\n",
    "\n",
    "\n",
    "\n",
    "sequence = \"MVI_40181\"\n",
    "fg = UADETRACFrameGrabber()           \n",
    "fg.open_sequence(sequence)\n",
    "\n",
    "\n",
    "save_path = Path(\"uadetrac_dataset/uadetrac_vid_roi_ann.csv\")\n",
    "geometry_df = pd.read_csv(save_path, converters={\"ROI\": eval, \"line\": eval})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "coco_vehicle_names = {\n",
    "    1: \"bicycle\",\n",
    "    2: \"car\",\n",
    "    3: \"motorcycle\",\n",
    "    5: \"bus\",\n",
    "    7: \"truck\",\n",
    "}\n",
    "tracking_method = \"ocsort\"\n",
    "tracker = Tracker(tracking_method , classes=list(coco_vehicle_names.keys()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# geometry lookup by stem match\n",
    "geom_mask = geometry_df['video'].astype(str).apply(lambda s: Path(s).stem == Path(sequence).stem)\n",
    "if geom_mask.any():\n",
    "    geom_row = geometry_df.loc[geom_mask].iloc[0]\n",
    "    polygon = geom_row.get(\"ROI\", None)\n",
    "    line = geom_row.get(\"line\", None)\n",
    "else:\n",
    "    polygon, line = None, None\n",
    "\n",
    "    \n",
    "COUNTING_MAP = {\n",
    "    \"counter_0\": [\"by_vicinity\"],\n",
    "    \"counter_1\": [\"by_id\"],\n",
    "    \"counter_2\": [\"by_cross_id\"],\n",
    "    \"counter_3\": [\"by_id\", \"by_vicinity\"],\n",
    "    \"counter_4\": [\"by_cross_id\", \"by_vicinity\"],\n",
    "    \"counter_5\": [\"by_cross_id\", \"by_id\", \"by_vicinity\"],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LINE_VICINITY = 0.05\n",
    "\n",
    "# instantiate counters according to COUNTING_MAP\n",
    "counters = {}\n",
    "for i, (cname, logic_list) in enumerate(COUNTING_MAP.items(), start=1):\n",
    "    roi_template = {\n",
    "        \"name\": cname,\n",
    "        \"enable\": True,\n",
    "        \"polygon\": polygon,\n",
    "        \"box_in_polygon_mode\": \"center_in_polygon\",\n",
    "        \"line\": line,\n",
    "        \"line_vicinity\": LINE_VICINITY,\n",
    "        \"counting_logic\": logic_list\n",
    "    }\n",
    "    counters[cname] = counter_load._normalize_roi(copy.deepcopy(roi_template), 0)\n",
    "\n",
    "\n",
    "\n",
    "# initial cumulative state\n",
    "prev_totals = {name: int(getattr(c.count_result, \"total_count\", 0)) for name, c in counters.items()}\n",
    "prev_bycls = {name: _make_prev_bycls(c) for name, c in counters.items()}\n",
    "\n",
    "\n",
    "# per-frame storage\n",
    "per_frame_store = {name: {\"total\": [], \"by_class\": [], \"timing_sec\": []} for name in counters}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with torch.inference_mode():\n",
    "# process frames (no inner tqdm to keep console compact)\n",
    "    for frame_idx, frame_data, frame_path in fg.frames(start=1):\n",
    "        if frame is not None:\n",
    "            \n",
    "            with pre_profile:\n",
    "                preprocessed_input = my_model.preprocess(frame_data)\n",
    "            with inf_profile:\n",
    "                raw_output = my_model.infer(preprocessed_input)   \n",
    "            with post_profile:\n",
    "                ready_to_track_array = my_model.postprocess(raw_output , preprocessed_input , frame_data)\n",
    "                \n",
    "            with track_profile:\n",
    "                res = tracker.update(ready_to_track_array , frame_data)\n",
    "\n",
    "            with counter_0_profile:\n",
    "                count_res0 = counters[\"counter_0\"].count(res)                \n",
    "            with counter_1_profile:\n",
    "                count_res1 = counters[\"counter_1\"].count(res)\n",
    "            with counter_2_profile:\n",
    "                count_res2 = counters[\"counter_2\"].count(res)\n",
    "            with counter_3_profile:\n",
    "                count_res3 = counters[\"counter_3\"].count(res)\n",
    "            with counter_4_profile:\n",
    "                count_res4 = counters[\"counter_4\"].count(res)\n",
    "            with counter_5_profile:\n",
    "                count_res5 = counters[\"counter_5\"].count(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeed4fa-c16a-453e-b478-578607373e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_vehicle_names = {\n",
    "    1: \"bicycle\",\n",
    "    2: \"car\",\n",
    "    3: \"motorcycle\",\n",
    "    5: \"bus\",\n",
    "    7: \"truck\",\n",
    "}\n",
    "\n",
    "tracker.target_classes , list(coco_vehicle_names.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09fff77-5b47-41ed-84b9-a12d24905efd",
   "metadata": {},
   "source": [
    "0.01 is very bad for trackerless algo (overcounting) and undercounting to vicinity based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d8e03a-722d-465e-9a00-c469ac0776b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_res0 , count_res1 , count_res2 , count_res3, count_res4 , count_res5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d471e-2b3a-44f4-a442-9aa57c097a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_profile.dt*1000 , inf_profile.dt*1000 , post_profile.dt*1000 , track_profile.dt*1000 , count_profile.dt*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecff24e-1da1-48a8-bad7-48d0c9880597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, torch\n",
    "\n",
    "class Profile:\n",
    "    def __init__(self, device=None):\n",
    "        self.device = device\n",
    "        self.use_cuda = bool(device and str(device).startswith(\"cuda\") and torch.cuda.is_available())\n",
    "        self.t = 0.0\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start_cpu = time.perf_counter()\n",
    "        if self.use_cuda:\n",
    "            self.start_ev = torch.cuda.Event(enable_timing=True)\n",
    "            self.end_ev = torch.cuda.Event(enable_timing=True)\n",
    "            self.start_ev.record()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc, tb):\n",
    "        if self.use_cuda:\n",
    "            self.end_ev.record()\n",
    "            torch.cuda.synchronize(self.device)   # ensure GPU work done\n",
    "            gpu_ms = self.start_ev.elapsed_time(self.end_ev)\n",
    "            self.gpu_time = gpu_ms / 1000.0\n",
    "        else:\n",
    "            self.gpu_time = 0.0\n",
    "        self.cpu_time = time.perf_counter() - self.start_cpu\n",
    "        # cpu_time is the wall-clock including GPU work (because we synchronized)\n",
    "        self.dt = self.cpu_time\n",
    "        self.t += self.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0d5de-6acc-42bc-8b3c-0a11f08937e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = my_model.predictor.device\n",
    "\n",
    "inf_profile = Profile(device=device)\n",
    "pre_profile = Profile(device=device)\n",
    "post_profile = Profile(device=device)\n",
    "\n",
    "track_profile = Profile()\n",
    "\n",
    "counter_0_profile = Profile()\n",
    "counter_1_profile = Profile()\n",
    "counter_2_profile = Profile()\n",
    "counter_3_profile = Profile()\n",
    "counter_4_profile = Profile()\n",
    "counter_5_profile = Profile()\n",
    "\n",
    "grabber_profile = Profile()\n",
    "all_profile = Profile(device=device)\n",
    "loop_profile = Profile(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8767bafb-661a-4f50-aa3a-86f247b65f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f605f833-b2ec-4a50-b6e8-2ec8d6bacca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
