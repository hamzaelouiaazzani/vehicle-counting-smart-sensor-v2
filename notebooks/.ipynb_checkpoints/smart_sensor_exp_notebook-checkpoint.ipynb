{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hamza\\\\Programs\\\\Road_Traffic_Monitoring_AI_Vision_Based_SMART_sensor\\\\Notebooks'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\Programs\\Road_Traffic_Monitoring_AI_Vision_Based_SMART_sensor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\anaconda3\\envs\\smart_sensor\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "\n",
    "# from ultralytics import YOLO , RTDETR\n",
    "# from ultralytics.utils import ops\n",
    "# from boxmot.engine.detectors import is_ultralytics_model , is_yolox_model , default_imgsz, get_yolo_inferer\n",
    "# from ultralytics.utils.checks import check_imgsz\n",
    "\n",
    "\n",
    "# from framegrabber.frame_grabber import FrameGrabber\n",
    "# from detection.ultralytics_detectors import UltralyticsDetector\n",
    "# from tracking.track import Tracker\n",
    "# from counting.count import Counter\n",
    "# from utils.shape_setter import PointSelector , LineSelector , TwoLineSelector , PolygonSelector , RectangleSelector , OBBSelector\n",
    "# from counting.count import Counter , CountResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from geometry.homography import Homography , compute_homography , save_calibration_yaml\n",
    "\n",
    "from framegrabber.frame_grabber import FrameGrabber\n",
    "\n",
    "import cv2\n",
    "\n",
    "source = \"vid1.mp4\"                   # 0 \"kech.mp4\"\n",
    "stride = 1\n",
    "stride_method = \"periodic_stride\"             # \"burst_stride\", \"periodic_stride\", \"random_sampling\"\n",
    "\n",
    "frame_grabber = FrameGrabber(source,\n",
    "                             stride=stride,\n",
    "                             stride_method=stride_method,\n",
    "                             window_size=20,\n",
    "                             queue_maxsize=10,\n",
    "                             grabber_mode = \"queue\",\n",
    "                             fallback_fps=30,\n",
    "                             allow_dynamic_resolution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (586,555), (887, 649), (695, 269), (865, 274), (1273, 620)\n",
    "# (0,0) ,   (2.1, -0.8), (2.1, 13) , (6.2,13)  , (6.2, -0.7)\n",
    "\n",
    "# (552, 242), (331, 225), (512, 587), (307, 579)\n",
    "# (-0.4, 13), (-6, 13),  (-0.4, -0.5), (-2,-0.5) \n",
    "                          \n",
    "image_pts = [\n",
    "    (586,555),\n",
    "    (887, 649),\n",
    "    (695, 269),\n",
    "    (865, 274),\n",
    "    (1273, 620),\n",
    "\n",
    "    (552, 242),\n",
    "    (331, 225),\n",
    "    (512, 587),\n",
    "    (307, 579)\n",
    "]\n",
    "# The world coordinates for the same points (meters on road plane)\n",
    "world_pts = [\n",
    "    (0,0),   # bottom-left\n",
    "    (2.1, -0.8),   # bottom-right (5m to the right)\n",
    "    (2.1, 13),\n",
    "    (6.2, 13),\n",
    "    (6.2, -0.7),\n",
    "\n",
    "    (-0.4, 13),\n",
    "    (-6, 13),\n",
    "    (-0.4, -0.5),\n",
    "    (-2, -0.5)\n",
    "]\n",
    "\n",
    "\n",
    "print(\"Computing homography from example correspondences...\")\n",
    "cal = compute_homography(image_pts, world_pts, method=\"ransac\", ransac_thresh_px=4.0, source=\"example\", version=\"v1\")\n",
    "cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"configs/cam01_homography.yaml\")\n",
    "print(f\"Saving calibration (rmse={cal.rmse:.3f} {cal.units}) to {out_path}\")\n",
    "save_calibration_yaml(cal, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homo = Homography(cal)\n",
    "p_test = (288, 418)                   # (612, 265)   (288, 418)\n",
    "\n",
    "world = homo.project_pixels_to_world([p_test])[0]\n",
    "print(f\"Pixel {p_test} -> world {world} ({cal.units})\")\n",
    "\n",
    "mpx, mpy, avg = homo.compute_local_scale(p_test)\n",
    "print(f\"Local meters-per-pixel: x={mpx:.4f}, y={mpy:.4f}, avg={avg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose bird-eye parameters (tune to your scene)\n",
    "meters_per_pixel = 0.005   # 5 cm / px (bigger => smaller image, faster)\n",
    "# Define world bounding box to render (units = meters, in your world coordinate system)\n",
    "Xmin, Xmax = -8, 8    # width in meters you want to cover\n",
    "Ymin, Ymax = -3, 14    # length in meters (from camera reference)\n",
    "dst_w = max(1, int((Xmax - Xmin) / meters_per_pixel))\n",
    "dst_h = max(1, int((Ymax - Ymin) / meters_per_pixel))\n",
    "dst_size = (dst_w, dst_h)\n",
    "origin_world = (Xmin, Ymin)   # world coords that map to top-left of bird image\n",
    "\n",
    "\n",
    "# optionally cap size for performance\n",
    "MAX_PIXELS = 1100  # e.g., cap max longer dimension\n",
    "scale = max(dst_w, dst_h) / MAX_PIXELS\n",
    "if scale > 1:\n",
    "    dst_size = (int(dst_w / scale), int(dst_h / scale))\n",
    "    meters_per_pixel = (Xmax - Xmin) / dst_size[0]   # update scale if you changed size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not frame_grabber.open():\n",
    "    raise RuntimeError(\"Failed to open source\")\n",
    "# ensure window exists (main thread)\n",
    "cv2.namedWindow('BoXMOT + ultralytics', cv2.WINDOW_NORMAL)\n",
    "if frame_grabber._grabber_mode==\"queue\":\n",
    "# start producer\n",
    "    frame_grabber.start()\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "# inside your existing loop, replace/extend where you have `frame`\n",
    "    while True:\n",
    "        frame = frame_grabber.get_frame(timeout=0.1)\n",
    "        if frame is None:\n",
    "            continue\n",
    "\n",
    "        if frame is not None:\n",
    "                \n",
    "            img = frame.data  # expected: HxWx3 BGR numpy array\n",
    "        \n",
    "            # produce bird's-eye image (top-down array)\n",
    "            bird = homo.warp_to_birdseye(\n",
    "                frame=img,\n",
    "                dst_size=dst_size,\n",
    "                origin_world=origin_world,\n",
    "                meters_per_pixel=meters_per_pixel,\n",
    "                border_value=0\n",
    "            )\n",
    "            bird = cv2.flip(bird, 0)\n",
    "            cv2.imshow('BoXMOT + ultralytics', bird)\n",
    "        \n",
    "                    \n",
    "        # ALWAYS poll keyboard events so 'q' is detected even when no frame was available\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            # stop producer and break loop\n",
    "            if frame_grabber._grabber_mode==\"queue\":\n",
    "                frame_grabber.stop(wait=True)\n",
    "            break\n",
    "\n",
    "        # optional: also break when producer finished (sentinel)\n",
    "        if frame_grabber._grabber_mode==\"queue\":\n",
    "            if frame is None and frame_grabber._stop_event.is_set():\n",
    "                break\n",
    "                \n",
    "finally:\n",
    "    frame_grabber.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
