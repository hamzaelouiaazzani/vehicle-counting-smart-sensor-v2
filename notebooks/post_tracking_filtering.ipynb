{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ef22f5-177f-4de3-a1da-45a7b78a3788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hamza\\\\Programs\\\\Road_Traffic_Monitoring_AI_Vision_Based_SMART_sensor\\\\notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913716b-cfcf-4885-a3c8-7185f0efb955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4915f48-6631-46bb-a836-3d0f6804b652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\Programs\\Road_Traffic_Monitoring_AI_Vision_Based_SMART_sensor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamza\\anaconda3\\envs\\smart_sensor\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "214d3ddb-65ba-48e3-a7d5-5301a61f2bda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.5  Python-3.10.18 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3050 6GB Laptop GPU, 6144MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,932 parameters, 0 gradients, 6.3 GFLOPs\n",
      "Successfully yolo11n_finetuned.pt model is initialized and warmedup !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-12 19:16:03.453\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36mC:\\Users\\hamza\\anaconda3\\envs\\smart_sensor\\lib\\site-packages\\boxmot\\trackers\\basetracker.py\u001b[0m:\u001b[36m56\u001b[0m | __init__ - \u001b[1mBaseTracker initialization parameters:\u001b[0m\n",
      "\u001b[32m2026-02-12 19:16:03.455\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36mC:\\Users\\hamza\\anaconda3\\envs\\smart_sensor\\lib\\site-packages\\boxmot\\trackers\\basetracker.py\u001b[0m:\u001b[36m57\u001b[0m | __init__ - \u001b[1mdet_thresh: 0.3\u001b[0m\n",
      "\u001b[32m2026-02-12 19:16:03.456\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36mC:\\Users\\hamza\\anaconda3\\envs\\smart_sensor\\lib\\site-packages\\boxmot\\trackers\\basetracker.py\u001b[0m:\u001b[36m58\u001b[0m | __init__ - \u001b[1mmax_age: 30\u001b[0m\n",
      "\u001b[32m2026-02-12 19:16:03.456\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36mC:\\Users\\hamza\\anaconda3\\envs\\smart_sensor\\lib\\site-packages\\boxmot\\trackers\\basetracker.py\u001b[0m:\u001b[36m59\u001b[0m | __init__ - \u001b[1mmax_obs: 50\u001b[0m\n",
      "\u001b[32m2026-02-12 19:16:03.456\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36mC:\\Users\\hamza\\anaconda3\\envs\\smart_sensor\\lib\\site-packages\\boxmot\\trackers\\basetracker.py\u001b[0m:\u001b[36m60\u001b[0m | __init__ - \u001b[1mmin_hits: 3\u001b[0m\n",
      "\u001b[32m2026-02-12 19:16:03.456\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36mC:\\Users\\hamza\\anaconda3\\envs\\smart_sensor\\lib\\site-packages\\boxmot\\trackers\\basetracker.py\u001b[0m:\u001b[36m61\u001b[0m | __init__ - \u001b[1miou_threshold: 0.3\u001b[0m\n",
      "\u001b[32m2026-02-12 19:16:03.456\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36mC:\\Users\\hamza\\anaconda3\\envs\\smart_sensor\\lib\\site-packages\\boxmot\\trackers\\basetracker.py\u001b[0m:\u001b[36m62\u001b[0m | __init__ - \u001b[1mper_class: True\u001b[0m\n",
      "\u001b[32m2026-02-12 19:16:03.456\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36mC:\\Users\\hamza\\anaconda3\\envs\\smart_sensor\\lib\\site-packages\\boxmot\\trackers\\basetracker.py\u001b[0m:\u001b[36m63\u001b[0m | __init__ - \u001b[1mnr_classes: 80\u001b[0m\n",
      "\u001b[32m2026-02-12 19:16:03.456\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36mC:\\Users\\hamza\\anaconda3\\envs\\smart_sensor\\lib\\site-packages\\boxmot\\trackers\\basetracker.py\u001b[0m:\u001b[36m64\u001b[0m | __init__ - \u001b[1masso_func: iou\u001b[0m\n",
      "\u001b[32m2026-02-12 19:16:03.458\u001b[0m | MainProcess/MainThread | \u001b[1mINFO    \u001b[0m | \u001b[36mC:\\Users\\hamza\\anaconda3\\envs\\smart_sensor\\lib\\site-packages\\boxmot\\trackers\\basetracker.py\u001b[0m:\u001b[36m65\u001b[0m | __init__ - \u001b[1mis_obb: False\u001b[0m\n",
      "\u001b[32m2026-02-12 19:16:03.459\u001b[0m | MainProcess/MainThread | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mC:\\Users\\hamza\\anaconda3\\envs\\smart_sensor\\lib\\site-packages\\boxmot\\trackers\\bytetrack\\bytetrack.py\u001b[0m:\u001b[36m205\u001b[0m | __init__ - \u001b[32m\u001b[1mInitialized ByteTrack\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "from framegrabber.frame_grabber import FrameGrabber\n",
    "\n",
    "from detection.ultralytics_detectors import UltralyticsDetector\n",
    "\n",
    "from tracking.track import Tracker\n",
    "\n",
    "from counting.count_config_loader import CountingConfigLoader\n",
    "from counting.count_visualizer import CountVisualizer\n",
    "\n",
    "#####################################################################################################################################\n",
    "\n",
    "my_model = UltralyticsDetector(\"yolo11n_finetuned.pt\" , conf=0.50)         # rtdetr-l.pt  yolo11n.pt yolo26n.pt yolo11n_finetuned\n",
    "coco_vehicles = [1, 2, 3, 5, 7]\n",
    "vehicles_4_wheels = [2, 5, 7]\n",
    "device = my_model.predictor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51fd0da8-ad93-4c38-bbae-fafee711fe64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, [640])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.predictor.args.conf , my_model.predictor.args.imgsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f681cc-869b-4baf-b639-442bb3ed32ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detection.torchvision_detectors import TorchvisionDetector\n",
    "\n",
    "det = TorchvisionDetector(\n",
    "    \"fasterrcnn_resnet50_fpn_v2\",\n",
    "    conf=0.6,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "# detections = det.detect_to_track(frame.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230f91d-982b-4d45-a1d7-cea3933eb019",
   "metadata": {},
   "source": [
    "* yolo26n: YOLO26n summary (fused): 122 layers, 2,408,932 parameters, 0 gradients, 5.4 GFLOPs\n",
    "* YOLOv8n summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
    "* YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189114a-35bf-4206-9498-c9be34853dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7bb282-6231-4b69-bbeb-3530e863f132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa97077-70d5-4291-9c9d-86fd7c074617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079f2035-213d-4b17-8c76-d88f71a87eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<counting.count.CountingROIWithIds at 0x14d0d4ebac0>,\n",
       " <counting.count.CountingROIWithIds at 0x14d13c39b70>,\n",
       " <counting.count.CountingGlobalAreaWithIds at 0x14d13b24640>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ordered_counters(*counters):\n",
    "    \"\"\"\n",
    "    Accepts:\n",
    "      ([roi1, roi2], global_ctr)\n",
    "      or\n",
    "      ([roi1, roi2, global_ctr],)\n",
    "\n",
    "    Returns:\n",
    "      flat, ordered list of counter objects\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- flatten ----\n",
    "    flat = []\n",
    "    for c in counters:\n",
    "        if isinstance(c, (list, tuple)):\n",
    "            flat.extend(c)\n",
    "        else:\n",
    "            flat.append(c)\n",
    "\n",
    "    # ---- semantic order ----\n",
    "    def key(ctr):\n",
    "        info = ctr.get_area_info()\n",
    "        # ROI / line first, global last\n",
    "        if info.get(\"polygon\") is not None or info.get(\"line\") is not None:\n",
    "            return (0, info.get(\"name\", \"\"))\n",
    "        return (1, info.get(\"name\", \"\"))\n",
    "\n",
    "    return sorted(flat, key=key)\n",
    "\n",
    "    \n",
    "count_vis = CountVisualizer(\n",
    "    show_legend=False,   # hide class legend\n",
    "    show_summary=True    # keep total summary box\n",
    ")\n",
    "\n",
    "counter_load = CountingConfigLoader()\n",
    "\n",
    "counters = counter_load.load_counting_areas()\n",
    "\n",
    "counters = ordered_counters(*counters)\n",
    "counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69f54edb-409f-410f-a408-db99b5f50140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.profilers import Profile\n",
    "\n",
    "device = my_model.predictor.device\n",
    "inf_profile = Profile(device=device)\n",
    "pre_profile = Profile(device=device)\n",
    "post_profile = Profile(device=device)\n",
    "track_profile = Profile()\n",
    "count_profile = Profile()\n",
    "grabber_profile = Profile()\n",
    "plot_profile = Profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c8d86e0-32a9-4469-bc6c-ae5648eefd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_method = \"bytetrack\"\n",
    "tracker = Tracker(tracking_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "405b0672-a2d7-4c35-b1c8-6e1b560bcd4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# source = r\"C:\\Users\\hamza\\Datasets\\TrafficDatasets\\IMAROC_2\\kech66.mp4\"                   # 0 \"kech.mp4\" , \"vid1.mp4\"\n",
    "# stride = 3\n",
    "# stride_method = \"periodic_stride\"             # \"burst_stride\", \"periodic_stride\", \"random_sampling\"\n",
    "\n",
    "# frame_grabber = FrameGrabber(source, stride=stride, stride_method=stride_method)\n",
    "\n",
    "\n",
    "# if not frame_grabber.open():\n",
    "#     raise RuntimeError(\"Failed to open source\")\n",
    "# # ensure window exists (main thread)\n",
    "# if frame_grabber._grabber_mode==\"queue\":\n",
    "# # start producer\n",
    "#     frame_grabber.start()\n",
    "\n",
    "# try:\n",
    "#     with torch.inference_mode():\n",
    "#         while True:\n",
    "#             with grabber_profile:\n",
    "#                 # try to get a frame but don't block forever\n",
    "#                 frame = frame_grabber.get_frame(timeout=0.1)  # <-- short timeout keeps loop responsive\n",
    "                    \n",
    "#             if frame is not None:\n",
    "#                 print(f\"frame_grabber index: {frame.read_idx}\")\n",
    "\n",
    "#                 with inf_profile:\n",
    "#                     ready_to_track_array = my_model.detect_to_track(frame.data)\n",
    "                    \n",
    "#                 with track_profile:\n",
    "#                     res = tracker.update(ready_to_track_array , frame.data)\n",
    "                    \n",
    "#                 det_array_plot = my_model.plot()\n",
    "\n",
    "\n",
    "#                 with count_profile:\n",
    "#                     g_count = counters[0].count(res)\n",
    "                    \n",
    "#                 # mark processed & show\n",
    "#                 frame_grabber.mark_processed(frame)\n",
    "\n",
    "                \n",
    "#             else:\n",
    "#                 # no frame this iteration (timeout), you may choose to display a placeholder\n",
    "#                 # or simply continue — but still poll for key events below\n",
    "#                 break\n",
    "\n",
    "# finally:\n",
    "#     frame_grabber.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51704155-cfad-470c-82d1-1eb15a234733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_count.total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cffd98-0beb-4488-9fcd-572ecdfd6e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541aa27-3cb9-4caf-b086-14f55d1d7acc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bd6cfd9-94fd-4809-a3e3-8aec7c7b6647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_grabber index: 0\n",
      "frame_grabber index: 2\n",
      "frame_grabber index: 4\n",
      "frame_grabber index: 6\n",
      "frame_grabber index: 8\n",
      "frame_grabber index: 10\n",
      "frame_grabber index: 12\n",
      "frame_grabber index: 14\n",
      "frame_grabber index: 16\n",
      "frame_grabber index: 18\n",
      "frame_grabber index: 20\n",
      "frame_grabber index: 22\n",
      "frame_grabber index: 24\n",
      "frame_grabber index: 26\n",
      "frame_grabber index: 28\n",
      "frame_grabber index: 30\n",
      "frame_grabber index: 32\n",
      "frame_grabber index: 34\n",
      "frame_grabber index: 36\n",
      "frame_grabber index: 38\n",
      "frame_grabber index: 40\n",
      "frame_grabber index: 42\n",
      "frame_grabber index: 44\n",
      "frame_grabber index: 46\n",
      "frame_grabber index: 48\n",
      "frame_grabber index: 50\n",
      "frame_grabber index: 52\n",
      "frame_grabber index: 54\n",
      "frame_grabber index: 56\n",
      "frame_grabber index: 58\n",
      "frame_grabber index: 60\n",
      "frame_grabber index: 62\n",
      "frame_grabber index: 64\n",
      "frame_grabber index: 66\n",
      "frame_grabber index: 68\n",
      "frame_grabber index: 70\n",
      "frame_grabber index: 72\n",
      "frame_grabber index: 74\n",
      "frame_grabber index: 76\n",
      "frame_grabber index: 78\n",
      "frame_grabber index: 80\n",
      "frame_grabber index: 82\n",
      "frame_grabber index: 84\n",
      "frame_grabber index: 86\n",
      "frame_grabber index: 88\n",
      "frame_grabber index: 90\n",
      "frame_grabber index: 92\n",
      "frame_grabber index: 94\n",
      "frame_grabber index: 96\n",
      "frame_grabber index: 98\n",
      "frame_grabber index: 100\n",
      "frame_grabber index: 102\n",
      "frame_grabber index: 104\n",
      "frame_grabber index: 106\n",
      "frame_grabber index: 108\n",
      "frame_grabber index: 110\n",
      "frame_grabber index: 112\n",
      "frame_grabber index: 114\n",
      "frame_grabber index: 116\n",
      "frame_grabber index: 118\n",
      "frame_grabber index: 120\n",
      "frame_grabber index: 122\n",
      "frame_grabber index: 124\n",
      "frame_grabber index: 126\n",
      "frame_grabber index: 128\n",
      "frame_grabber index: 130\n",
      "frame_grabber index: 132\n",
      "frame_grabber index: 134\n",
      "frame_grabber index: 136\n",
      "frame_grabber index: 138\n",
      "frame_grabber index: 140\n",
      "frame_grabber index: 142\n",
      "frame_grabber index: 144\n",
      "frame_grabber index: 146\n",
      "frame_grabber index: 148\n",
      "frame_grabber index: 150\n",
      "frame_grabber index: 152\n",
      "frame_grabber index: 154\n",
      "frame_grabber index: 156\n",
      "frame_grabber index: 158\n",
      "frame_grabber index: 160\n",
      "frame_grabber index: 162\n",
      "frame_grabber index: 164\n",
      "frame_grabber index: 166\n",
      "frame_grabber index: 168\n",
      "frame_grabber index: 170\n",
      "frame_grabber index: 172\n",
      "frame_grabber index: 174\n",
      "frame_grabber index: 176\n",
      "frame_grabber index: 178\n",
      "frame_grabber index: 180\n",
      "frame_grabber index: 182\n",
      "frame_grabber index: 184\n",
      "frame_grabber index: 186\n",
      "frame_grabber index: 188\n",
      "frame_grabber index: 190\n",
      "frame_grabber index: 192\n",
      "frame_grabber index: 194\n",
      "frame_grabber index: 196\n",
      "frame_grabber index: 198\n",
      "frame_grabber index: 200\n",
      "frame_grabber index: 202\n",
      "frame_grabber index: 204\n",
      "frame_grabber index: 206\n",
      "frame_grabber index: 208\n",
      "frame_grabber index: 210\n",
      "frame_grabber index: 212\n",
      "frame_grabber index: 214\n",
      "frame_grabber index: 216\n",
      "frame_grabber index: 218\n",
      "frame_grabber index: 220\n",
      "frame_grabber index: 222\n",
      "frame_grabber index: 224\n",
      "frame_grabber index: 226\n",
      "frame_grabber index: 228\n",
      "frame_grabber index: 230\n",
      "frame_grabber index: 232\n",
      "frame_grabber index: 234\n",
      "frame_grabber index: 236\n",
      "frame_grabber index: 238\n",
      "frame_grabber index: 240\n",
      "frame_grabber index: 242\n",
      "frame_grabber index: 244\n",
      "frame_grabber index: 246\n",
      "frame_grabber index: 248\n",
      "frame_grabber index: 250\n",
      "frame_grabber index: 252\n",
      "frame_grabber index: 254\n",
      "frame_grabber index: 256\n",
      "frame_grabber index: 258\n",
      "frame_grabber index: 260\n",
      "frame_grabber index: 262\n",
      "frame_grabber index: 264\n",
      "frame_grabber index: 266\n",
      "frame_grabber index: 268\n",
      "frame_grabber index: 270\n",
      "frame_grabber index: 272\n",
      "frame_grabber index: 274\n",
      "frame_grabber index: 276\n",
      "frame_grabber index: 278\n",
      "frame_grabber index: 280\n",
      "frame_grabber index: 282\n",
      "frame_grabber index: 284\n",
      "frame_grabber index: 286\n",
      "frame_grabber index: 288\n",
      "frame_grabber index: 290\n",
      "frame_grabber index: 292\n",
      "frame_grabber index: 294\n",
      "frame_grabber index: 296\n",
      "frame_grabber index: 298\n",
      "frame_grabber index: 300\n",
      "frame_grabber index: 302\n",
      "frame_grabber index: 304\n",
      "frame_grabber index: 306\n",
      "frame_grabber index: 308\n",
      "frame_grabber index: 310\n",
      "frame_grabber index: 312\n",
      "frame_grabber index: 314\n",
      "frame_grabber index: 316\n",
      "frame_grabber index: 318\n",
      "frame_grabber index: 320\n",
      "frame_grabber index: 322\n",
      "frame_grabber index: 324\n",
      "frame_grabber index: 326\n",
      "frame_grabber index: 328\n",
      "frame_grabber index: 330\n",
      "frame_grabber index: 332\n",
      "frame_grabber index: 334\n",
      "frame_grabber index: 336\n",
      "frame_grabber index: 338\n",
      "frame_grabber index: 340\n",
      "frame_grabber index: 342\n",
      "frame_grabber index: 344\n",
      "frame_grabber index: 346\n",
      "frame_grabber index: 348\n",
      "frame_grabber index: 350\n",
      "frame_grabber index: 352\n",
      "frame_grabber index: 354\n",
      "frame_grabber index: 356\n",
      "frame_grabber index: 358\n",
      "frame_grabber index: 360\n",
      "frame_grabber index: 362\n",
      "frame_grabber index: 364\n",
      "frame_grabber index: 366\n",
      "frame_grabber index: 368\n",
      "frame_grabber index: 370\n",
      "frame_grabber index: 372\n",
      "frame_grabber index: 374\n",
      "frame_grabber index: 376\n",
      "frame_grabber index: 378\n",
      "frame_grabber index: 380\n",
      "frame_grabber index: 382\n",
      "frame_grabber index: 384\n",
      "frame_grabber index: 386\n",
      "frame_grabber index: 388\n",
      "frame_grabber index: 390\n",
      "frame_grabber index: 392\n",
      "frame_grabber index: 394\n",
      "frame_grabber index: 396\n",
      "frame_grabber index: 398\n",
      "frame_grabber index: 400\n",
      "frame_grabber index: 402\n",
      "frame_grabber index: 404\n",
      "frame_grabber index: 406\n",
      "frame_grabber index: 408\n",
      "frame_grabber index: 410\n",
      "frame_grabber index: 412\n",
      "frame_grabber index: 414\n",
      "frame_grabber index: 416\n",
      "frame_grabber index: 418\n",
      "frame_grabber index: 420\n",
      "frame_grabber index: 422\n",
      "frame_grabber index: 424\n",
      "frame_grabber index: 426\n",
      "frame_grabber index: 428\n",
      "frame_grabber index: 430\n",
      "frame_grabber index: 432\n",
      "frame_grabber index: 434\n",
      "frame_grabber index: 436\n",
      "frame_grabber index: 438\n",
      "frame_grabber index: 440\n",
      "frame_grabber index: 442\n",
      "frame_grabber index: 444\n",
      "frame_grabber index: 446\n",
      "frame_grabber index: 448\n",
      "frame_grabber index: 450\n",
      "frame_grabber index: 452\n",
      "frame_grabber index: 454\n",
      "frame_grabber index: 456\n",
      "frame_grabber index: 458\n",
      "frame_grabber index: 460\n",
      "frame_grabber index: 462\n",
      "frame_grabber index: 464\n",
      "frame_grabber index: 466\n",
      "frame_grabber index: 468\n",
      "frame_grabber index: 470\n",
      "frame_grabber index: 472\n",
      "frame_grabber index: 474\n",
      "frame_grabber index: 476\n",
      "frame_grabber index: 478\n",
      "frame_grabber index: 480\n",
      "frame_grabber index: 482\n",
      "frame_grabber index: 484\n",
      "frame_grabber index: 486\n",
      "frame_grabber index: 488\n",
      "frame_grabber index: 490\n",
      "frame_grabber index: 492\n",
      "frame_grabber index: 494\n",
      "frame_grabber index: 496\n",
      "frame_grabber index: 498\n",
      "frame_grabber index: 500\n",
      "frame_grabber index: 502\n",
      "frame_grabber index: 504\n",
      "frame_grabber index: 506\n",
      "frame_grabber index: 508\n",
      "frame_grabber index: 510\n",
      "frame_grabber index: 512\n",
      "frame_grabber index: 514\n",
      "frame_grabber index: 516\n",
      "frame_grabber index: 518\n",
      "frame_grabber index: 520\n",
      "frame_grabber index: 522\n",
      "frame_grabber index: 524\n",
      "frame_grabber index: 526\n",
      "frame_grabber index: 528\n",
      "frame_grabber index: 530\n",
      "frame_grabber index: 532\n",
      "frame_grabber index: 534\n",
      "frame_grabber index: 536\n",
      "frame_grabber index: 538\n",
      "frame_grabber index: 540\n",
      "frame_grabber index: 542\n",
      "frame_grabber index: 544\n",
      "frame_grabber index: 546\n",
      "frame_grabber index: 548\n",
      "frame_grabber index: 550\n",
      "frame_grabber index: 552\n",
      "frame_grabber index: 554\n",
      "frame_grabber index: 556\n",
      "frame_grabber index: 558\n",
      "frame_grabber index: 560\n",
      "frame_grabber index: 562\n",
      "frame_grabber index: 564\n",
      "frame_grabber index: 566\n",
      "frame_grabber index: 568\n",
      "frame_grabber index: 570\n",
      "frame_grabber index: 572\n",
      "frame_grabber index: 574\n",
      "frame_grabber index: 576\n",
      "frame_grabber index: 578\n",
      "frame_grabber index: 580\n",
      "frame_grabber index: 582\n",
      "frame_grabber index: 584\n",
      "frame_grabber index: 586\n",
      "frame_grabber index: 588\n",
      "frame_grabber index: 590\n",
      "frame_grabber index: 592\n",
      "frame_grabber index: 594\n",
      "frame_grabber index: 596\n",
      "frame_grabber index: 598\n",
      "frame_grabber index: 600\n",
      "frame_grabber index: 602\n",
      "frame_grabber index: 604\n",
      "frame_grabber index: 606\n",
      "frame_grabber index: 608\n",
      "frame_grabber index: 610\n",
      "frame_grabber index: 612\n",
      "frame_grabber index: 614\n",
      "frame_grabber index: 616\n",
      "frame_grabber index: 618\n",
      "frame_grabber index: 620\n",
      "frame_grabber index: 622\n",
      "frame_grabber index: 624\n",
      "frame_grabber index: 626\n",
      "frame_grabber index: 628\n",
      "frame_grabber index: 630\n",
      "frame_grabber index: 632\n",
      "frame_grabber index: 634\n",
      "frame_grabber index: 636\n",
      "frame_grabber index: 638\n",
      "frame_grabber index: 640\n",
      "frame_grabber index: 642\n",
      "frame_grabber index: 644\n",
      "frame_grabber index: 646\n",
      "frame_grabber index: 648\n",
      "frame_grabber index: 650\n",
      "frame_grabber index: 652\n",
      "frame_grabber index: 654\n",
      "frame_grabber index: 656\n",
      "frame_grabber index: 658\n",
      "frame_grabber index: 660\n",
      "frame_grabber index: 662\n",
      "frame_grabber index: 664\n",
      "frame_grabber index: 666\n",
      "frame_grabber index: 668\n",
      "frame_grabber index: 670\n",
      "frame_grabber index: 672\n",
      "frame_grabber index: 674\n",
      "frame_grabber index: 676\n",
      "frame_grabber index: 678\n",
      "frame_grabber index: 680\n",
      "frame_grabber index: 682\n",
      "frame_grabber index: 684\n",
      "frame_grabber index: 686\n",
      "frame_grabber index: 688\n",
      "frame_grabber index: 690\n",
      "frame_grabber index: 692\n",
      "frame_grabber index: 694\n",
      "frame_grabber index: 696\n",
      "frame_grabber index: 698\n",
      "frame_grabber index: 700\n",
      "frame_grabber index: 702\n",
      "frame_grabber index: 704\n",
      "frame_grabber index: 706\n",
      "frame_grabber index: 708\n",
      "frame_grabber index: 710\n",
      "frame_grabber index: 712\n",
      "frame_grabber index: 714\n",
      "frame_grabber index: 716\n",
      "frame_grabber index: 718\n",
      "frame_grabber index: 720\n",
      "frame_grabber index: 722\n",
      "frame_grabber index: 724\n",
      "frame_grabber index: 726\n",
      "frame_grabber index: 728\n",
      "frame_grabber index: 730\n",
      "frame_grabber index: 732\n",
      "frame_grabber index: 734\n",
      "frame_grabber index: 736\n",
      "frame_grabber index: 738\n",
      "frame_grabber index: 740\n",
      "frame_grabber index: 742\n",
      "frame_grabber index: 744\n",
      "frame_grabber index: 746\n",
      "frame_grabber index: 748\n",
      "frame_grabber index: 750\n",
      "frame_grabber index: 752\n",
      "frame_grabber index: 754\n"
     ]
    }
   ],
   "source": [
    "source = r\"C:\\Users\\hamza\\Datasets\\TrafficDatasets\\IMAROC_2\\kech37.mp4\"                   # 0 \"kech.mp4\" , \"vid1.mp4\"\n",
    "\n",
    "# --- Video writer setup ---\n",
    "output_path = \"output_counting_37_.mp4\"\n",
    "\n",
    "fps = 30\n",
    "\n",
    "# Get frame size (wait until first frame if needed)\n",
    "ret, test_cap = cv2.VideoCapture(source).read()\n",
    "h, w = test_cap.shape[:2]\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # widely supported\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n",
    "\n",
    "assert video_writer.isOpened(), \"Failed to open VideoWriter\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stride = 2\n",
    "stride_method = \"periodic_stride\"             # \"burst_stride\", \"periodic_stride\", \"random_sampling\"\n",
    "\n",
    "frame_grabber = FrameGrabber(source, stride=stride, stride_method=stride_method)\n",
    "\n",
    "\n",
    "if not frame_grabber.open():\n",
    "    raise RuntimeError(\"Failed to open source\")\n",
    "# ensure window exists (main thread)\n",
    "cv2.namedWindow('BoXMOT + ultralytics', cv2.WINDOW_NORMAL)\n",
    "if frame_grabber._grabber_mode==\"queue\":\n",
    "# start producer\n",
    "    frame_grabber.start()\n",
    "\n",
    "try:\n",
    "    with torch.inference_mode():\n",
    "        while True:\n",
    "            with grabber_profile:\n",
    "                # try to get a frame but don't block forever\n",
    "                frame = frame_grabber.get_frame(timeout=0.1)  # <-- short timeout keeps loop responsive\n",
    "                    \n",
    "            if frame is not None:\n",
    "                print(f\"frame_grabber index: {frame.read_idx}\")\n",
    "\n",
    "                with inf_profile:\n",
    "                    ready_to_track_array = my_model.detect_to_track(frame.data)\n",
    "   \n",
    "                with track_profile:\n",
    "                    res = tracker.update(ready_to_track_array , frame.data)\n",
    "                    # print(f\"tracking array: {res} for counter: {counters[2]}\")\n",
    "                # det_array_plot = my_model.plot()\n",
    "                # det_array_plot = det.plot(frame.data, detections)\n",
    "                \n",
    "                track_array_plot = tracker.tracker.plot_results(frame.data, show_trajectories=True)\n",
    "\n",
    "                with count_profile:\n",
    "                    g_count = counters[2].count(res)\n",
    "                    roi1_count = counters[0].count(res)\n",
    "                    roi2_count = counters[1].count(res)\n",
    "                    \n",
    "                with plot_profile:\n",
    "                    count_plot = count_vis.render(track_array_plot, *counters)\n",
    "\n",
    "\n",
    "                # --- WRITE FRAME TO VIDEO ---\n",
    "                video_writer.write(count_plot)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                # Speed\n",
    "                est.update(res, frame_idx=frame.read_idx, timestamp=None)\n",
    "                # speeds = est.get_and_clear_speeds()\n",
    "                if speeds:\n",
    "                    print(f\"Frame {frame}: computed speeds -> {speeds}\")\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "                # mark processed & show\n",
    "                frame_grabber.mark_processed(frame)\n",
    "\n",
    "                cv2.imshow('BoXMOT + ultralytics', count_plot)\n",
    "                \n",
    "            else:\n",
    "                # no frame this iteration (timeout), you may choose to display a placeholder\n",
    "                # or simply continue — but still poll for key events below\n",
    "                pass\n",
    "\n",
    "            # ALWAYS poll keyboard events so 'q' is detected even when no frame was available\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                # stop producer and break loop\n",
    "                if frame_grabber._grabber_mode==\"queue\":\n",
    "                    frame_grabber.stop(wait=True)\n",
    "                break\n",
    "    \n",
    "                # optional: also break when producer finished (sentinel)\n",
    "                if frame_grabber._grabber_mode==\"queue\":\n",
    "                    if frame is None and frame_grabber._stop_event.is_set():\n",
    "                        break\n",
    "finally:\n",
    "    frame_grabber.release()\n",
    "    video_writer.release()   # <-- ADD THIS\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c377a6-9773-4282-901f-7819eab1023d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239ada56-6fb4-4b02-a812-4a10d43b88d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0941db2e-70e9-4fda-8e44-813ad5cb0d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f551a0-ada1-40b1-b276-f05eefea00b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_count , roi1_count , roi2_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af078d6a-a7c3-4d9f-bf76-7c58d7cf69dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f43721-9021-429f-a20e-b7ad7aa8ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_count.total_count , g_count.counts_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725a1bf-6166-46f1-9416-ec04a6d9bd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e633a80-7fa4-4db6-b489-602f713fb748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected polygon: None\n"
     ]
    }
   ],
   "source": [
    "from utils.shape_setter import PointSelector , LineSelector , TwoLineSelector , PolygonSelector , RectangleSelector , OBBSelector\n",
    "import cv2\n",
    "import numpy as np\n",
    "source = r\"C:\\Users\\hamza\\Datasets\\TrafficDatasets\\IMAROC_2\\kech37.mp4\" \n",
    "\n",
    "stride = 1\n",
    "stride_method = \"periodic_stride\"             # \"burst_stride\", \"periodic_stride\", \"random_sampling\"\n",
    "\n",
    "cap = cv2.VideoCapture(source)\n",
    "ok, first_frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if not ok or first_frame is None:\n",
    "    print(\"Failed to read example frame; please provide a valid path ('kech.mp4' used in example).\")\n",
    "else:\n",
    "    # # line\n",
    "    # line_sel = LineSelector(max_display_size=900, auto_confirm=True, preview_wait_secs=None)\n",
    "    # line = line_sel.select_line(first_frame)\n",
    "    # print(\"Selected line:\", line)\n",
    "\n",
    "    # # two lines\n",
    "    # two_sel = TwoLineSelector(max_display_size=900, auto_confirm=True, preview_wait_secs=None)\n",
    "    # two = two_sel.select_two_lines(first_frame)\n",
    "    # print(\"Selected two lines:\", two)\n",
    "\n",
    "    #polygon\n",
    "    poly_sel = PolygonSelector(max_display_size=900, min_points=4, auto_close_on_click_near_first=True,\n",
    "                               close_pixel_radius=12, preview_wait_secs=None)\n",
    "    poly = poly_sel.select_polygon(first_frame)\n",
    "    print(\"Selected polygon:\", poly)\n",
    "\n",
    "    # # rectangle\n",
    "    # rect_sel = RectangleSelector(max_display_size=900, auto_confirm=True, preview_wait_secs=None)\n",
    "    # rect = rect_sel.select_rectangle(first_frame)\n",
    "    # if rect is None:\n",
    "    #     print(\"Cancelled\")\n",
    "    # else:\n",
    "    #     print(\"Selected rectangle:\", rect)\n",
    "\n",
    "\n",
    "    # # # obb£\n",
    "    # obb_selector = OBBSelector()\n",
    "    # obb_points = obb_selector.select_obb(first_frame)\n",
    "    # if obb_points is not None:\n",
    "    #     print(\"Selected OBB points:\", obb_points)\n",
    "    # else:\n",
    "    #     print(\"Selection cancelled\")\n",
    "\n",
    "\n",
    "    # selector = PointSelector()\n",
    "    # pt = selector.select_point(first_frame)\n",
    "    # print(\"Selected point:\", pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6345e6-4cf7-4531-b6b2-27e7a311b636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e6f58aa-787c-4b48-95db-1ca150c16507",
   "metadata": {},
   "source": [
    "* I need the sys metrics file\n",
    "* I need the actual counts\n",
    "* I need to understand why counting fails ?????? or it takes a very long time to operate !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66fe6db-4948-41a2-81cf-56c9fe807c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
